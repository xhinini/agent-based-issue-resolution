# Instance ID: scikit-learn__scikit-learn-25638
# Model: AppMap Navie GPT-4o

### Original Case Description and Gold Patch
# INSTANCE_ID: scikit-learn__scikit-learn-25638

### ISSUE TYPE
new feature

### DESCRIPTION
Support nullable pandas dtypes in `unique_labels`
### Describe the workflow you want to enable

I would like to be able to pass the nullable pandas dtypes ("Int64", "Float64", "boolean") into sklearn's `unique_labels` function. Because the dtypes become `object` dtype when converted to numpy arrays we get `ValueError: Mix type of y not allowed, got types {'binary', 'unknown'}`:

Repro with sklearn 1.2.1
```py 
    import pandas as pd
    import pytest
    from sklearn.utils.multiclass import unique_labels
    
    for dtype in ["Int64", "Float64", "boolean"]:
        y_true = pd.Series([1, 0, 0, 1, 0, 1, 1, 0, 1], dtype=dtype)
        y_predicted = pd.Series([0, 0, 1, 1, 0, 1, 1, 1, 1], dtype="int64")

        with pytest.raises(ValueError, match="Mix type of y not allowed, got types"):
            unique_labels(y_true, y_predicted)
```

### Describe your proposed solution

We should get the same behavior as when `int64`, `float64`, and `bool` dtypes are used, which is no error:  

```python
    import pandas as pd
    from sklearn.utils.multiclass import unique_labels
    
    for dtype in ["int64", "float64", "bool"]:
        y_true = pd.Series([1, 0, 0, 1, 0, 1, 1, 0, 1], dtype=dtype)
        y_predicted = pd.Series([0, 0, 1, 1, 0, 1, 1, 1, 1], dtype="int64")

        unique_labels(y_true, y_predicted)
```

### Describe alternatives you've considered, if relevant

Our current workaround is to convert the data to numpy arrays with the corresponding dtype that works prior to passing it into `unique_labels`.

### Additional context

_No response_


### GOLD_PATCH
diff --git a/sklearn/utils/multiclass.py b/sklearn/utils/multiclass.py
--- a/sklearn/utils/multiclass.py
+++ b/sklearn/utils/multiclass.py
@@ -155,14 +155,25 @@ def is_multilabel(y):
     if hasattr(y, "__array__") or isinstance(y, Sequence) or is_array_api:
         # DeprecationWarning will be replaced by ValueError, see NEP 34
         # https://numpy.org/neps/nep-0034-infer-dtype-is-object.html
+        check_y_kwargs = dict(
+            accept_sparse=True,
+            allow_nd=True,
+            force_all_finite=False,
+            ensure_2d=False,
+            ensure_min_samples=0,
+            ensure_min_features=0,
+        )
         with warnings.catch_warnings():
             warnings.simplefilter("error", np.VisibleDeprecationWarning)
             try:
-                y = xp.asarray(y)
-            except (np.VisibleDeprecationWarning, ValueError):
+                y = check_array(y, dtype=None, **check_y_kwargs)
+            except (np.VisibleDeprecationWarning, ValueError) as e:
+                if str(e).startswith("Complex data not supported"):
+                    raise
+
                 # dtype=object should be provided explicitly for ragged arrays,
                 # see NEP 34
-                y = xp.asarray(y, dtype=object)
+                y = check_array(y, dtype=object, **check_y_kwargs)
 
     if not (hasattr(y, "shape") and y.ndim == 2 and y.shape[1] > 1):
         return False
@@ -302,15 +313,27 @@ def type_of_target(y, input_name=""):
     # https://numpy.org/neps/nep-0034-infer-dtype-is-object.html
     # We therefore catch both deprecation (NumPy < 1.24) warning and
     # value error (NumPy >= 1.24).
+    check_y_kwargs = dict(
+        accept_sparse=True,
+        allow_nd=True,
+        force_all_finite=False,
+        ensure_2d=False,
+        ensure_min_samples=0,
+        ensure_min_features=0,
+    )
+
     with warnings.catch_warnings():
         warnings.simplefilter("error", np.VisibleDeprecationWarning)
         if not issparse(y):
             try:
-                y = xp.asarray(y)
-            except (np.VisibleDeprecationWarning, ValueError):
+                y = check_array(y, dtype=None, **check_y_kwargs)
+            except (np.VisibleDeprecationWarning, ValueError) as e:
+                if str(e).startswith("Complex data not supported"):
+                    raise
+
                 # dtype=object should be provided explicitly for ragged arrays,
                 # see NEP 34
-                y = xp.asarray(y, dtype=object)
+                y = check_array(y, dtype=object, **check_y_kwargs)
 
     # The old sequence of sequences format
     try:


### MODEL_OUTPUTS




### Model Generated Patch
diff --git a/sklearn/utils/multiclass.py b/sklearn/utils/multiclass.py
index 5eaef2fde..8e98e212e 100644
--- a/sklearn/utils/multiclass.py
+++ b/sklearn/utils/multiclass.py
@@ -4,11 +4,11 @@
 """
 Multi-class / multi-label utility function
 ==========================================
-
 """
 from collections.abc import Sequence
 from itertools import chain
 import warnings
+import pandas as pd
 
 from scipy.sparse import issparse
 from scipy.sparse import dok_matrix
@@ -43,26 +43,21 @@ _FN_UNIQUE_LABELS = {
 
 def unique_labels(*ys):
     """Extract an ordered array of unique labels.
-
     We don't allow:
         - mix of multilabel and multiclass (single label) targets
         - mix of label indicator matrix and anything else,
           because there are no explicit labels)
         - mix of label indicator matrices of different sizes
         - mix of string and integer labels
-
     At the moment, we also don't allow "multiclass-multioutput" input type.
-
     Parameters
     ----------
     *ys : array-likes
         Label values.
-
     Returns
     -------
     out : ndarray of shape (n_unique_labels,)
         An ordered array of unique labels.
-
     Examples
     --------
     >>> from sklearn.utils.multiclass import unique_labels
@@ -73,9 +68,22 @@ def unique_labels(*ys):
     >>> unique_labels([1, 2, 10], [5, 11])
     array([ 1,  2,  5, 10, 11])
     """
+    import pandas as pd
+
+    def convert_nullable_dtype(y):
+        if pd.api.types.is_integer_dtype(y):
+            return y.to_numpy(dtype="int64")
+        elif pd.api.types.is_float_dtype(y):
+            return y.to_numpy(dtype="float64")
+        elif pd.api.types.is_bool_dtype(y):
+            return y.to_numpy(dtype="bool")
+        return y
+
     xp, is_array_api = get_namespace(*ys)
     if not ys:
         raise ValueError("No argument has been passed.")
+    # Convert nullable dtypes to their numpy equivalents
+    ys = [convert_nullable_dtype(y) for y in ys]
     # Check that we don't mix label format
 
     ys_types = set(type_of_target(x) for x in ys)


### Test Output
+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /opt/miniconda3/bin/conda
++++ dirname /opt/miniconda3/bin
+++ PATH=/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\''
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libglib_activate.sh"'
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\''
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libglib_activate.sh"'
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_1=/opt/miniconda3
++ CONDA_PREFIX_1=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/libglib_activate.sh
+++ export GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
+++ GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
+++ export GSETTINGS_SCHEMA_DIR=/opt/miniconda3/envs/testbed/share/glib-2.0/schemas
+++ GSETTINGS_SCHEMA_DIR=/opt/miniconda3/envs/testbed/share/glib-2.0/schemas
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ cd /testbed
+ git config --global --add safe.directory /testbed
+ cd /testbed
+ git status
On branch main
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   sklearn/utils/multiclass.py

no changes added to commit (use "git add" and/or "git commit -a")
+ git show
commit 6adb209acd63825affc884abcd85381f148fb1b0
Author: Omar Salman <omar.salman@arbisoft.com>
Date:   Thu Feb 23 22:52:19 2023 +0500

    FIX renormalization of y_pred inside log_loss (#25299)
    
    * Remove renormalization of y_pred inside log_loss
    
    * Deprecate eps parameter in log_loss

diff --git a/doc/whats_new/v1.3.rst b/doc/whats_new/v1.3.rst
index 3e5e5083d..e7cd4c1a0 100644
--- a/doc/whats_new/v1.3.rst
+++ b/doc/whats_new/v1.3.rst
@@ -165,6 +165,13 @@ Changelog
 - |Fix| :func:`metric.manhattan_distances` now supports readonly sparse datasets.
   :pr:`25432` by :user:`Julien Jerphanion <jjerphan>`.
 
+- |Fix| :func:`log_loss` raises a warning if the values of the parameter `y_pred` are
+  not normalized, instead of actually normalizing them in the metric. Starting from
+  1.5 this will raise an error. :pr:`25299` by :user:`Omar Salman <OmarManzoor`.
+
+- |API| The `eps` parameter of the :func:`log_loss` has been deprecated and will be
+  removed in 1.5. :pr:`25299` by :user:`Omar Salman <OmarManzoor>`.
+
 :mod:`sklearn.naive_bayes`
 ..........................
 
diff --git a/sklearn/metrics/_classification.py b/sklearn/metrics/_classification.py
index bd8011a5b..0602ec77a 100644
--- a/sklearn/metrics/_classification.py
+++ b/sklearn/metrics/_classification.py
@@ -2622,6 +2622,9 @@ def log_loss(
            The default value changed from `1e-15` to `"auto"` that is
            equivalent to `np.finfo(y_pred.dtype).eps`.
 
+        .. deprecated:: 1.3
+           `eps` is deprecated in 1.3 and will be removed in 1.5.
+
     normalize : bool, default=True
         If true, return the mean loss per sample.
         Otherwise, return the sum of the per-sample losses.
@@ -2660,7 +2663,16 @@ def log_loss(
     y_pred = check_array(
         y_pred, ensure_2d=False, dtype=[np.float64, np.float32, np.float16]
     )
-    eps = np.finfo(y_pred.dtype).eps if eps == "auto" else eps
+    if eps == "auto":
+        eps = np.finfo(y_pred.dtype).eps
+    else:
+        # TODO: Remove user defined eps in 1.5
+        warnings.warn(
+            "Setting the eps parameter is deprecated and will "
+            "be removed in 1.5. Instead eps will always have"
+            "a default value of `np.finfo(y_pred.dtype).eps`.",
+            FutureWarning,
+        )
 
     check_consistent_length(y_pred, y_true, sample_weight)
     lb = LabelBinarizer()
@@ -2723,6 +2735,12 @@ def log_loss(
 
     # Renormalize
     y_pred_sum = y_pred.sum(axis=1)
+    if not np.isclose(y_pred_sum, 1, rtol=1e-15, atol=5 * eps).all():
+        warnings.warn(
+            "The y_pred values do not sum to one. Starting from 1.5 this"
+            "will result in an error.",
+            UserWarning,
+        )
     y_pred = y_pred / y_pred_sum[:, np.newaxis]
     loss = -xlogy(transformed_labels, y_pred).sum(axis=1)
 
diff --git a/sklearn/metrics/tests/test_classification.py b/sklearn/metrics/tests/test_classification.py
index 704b79add..222f44555 100644
--- a/sklearn/metrics/tests/test_classification.py
+++ b/sklearn/metrics/tests/test_classification.py
@@ -2477,19 +2477,29 @@ def test_log_loss():
     loss = log_loss(y_true, y_pred, normalize=False)
     assert_almost_equal(loss, 0.6904911 * 6, decimal=6)
 
+    user_warning_msg = "y_pred values do not sum to one"
     # check eps and handling of absolute zero and one probabilities
     y_pred = np.asarray(y_pred) > 0.5
-    loss = log_loss(y_true, y_pred, normalize=True, eps=0.1)
-    assert_almost_equal(loss, log_loss(y_true, np.clip(y_pred, 0.1, 0.9)))
+    with pytest.warns(FutureWarning):
+        loss = log_loss(y_true, y_pred, normalize=True, eps=0.1)
+    with pytest.warns(UserWarning, match=user_warning_msg):
+        assert_almost_equal(loss, log_loss(y_true, np.clip(y_pred, 0.1, 0.9)))
 
     # binary case: check correct boundary values for eps = 0
-    assert log_loss([0, 1], [0, 1], eps=0) == 0
-    assert log_loss([0, 1], [0, 0], eps=0) == np.inf
-    assert log_loss([0, 1], [1, 1], eps=0) == np.inf
+    with pytest.warns(FutureWarning):
+        assert log_loss([0, 1], [0, 1], eps=0) == 0
+    with pytest.warns(FutureWarning):
+        assert log_loss([0, 1], [0, 0], eps=0) == np.inf
+    with pytest.warns(FutureWarning):
+        assert log_loss([0, 1], [1, 1], eps=0) == np.inf
 
     # multiclass case: check correct boundary values for eps = 0
-    assert log_loss([0, 1, 2], [[1, 0, 0], [0, 1, 0], [0, 0, 1]], eps=0) == 0
-    assert log_loss([0, 1, 2], [[0, 0.5, 0.5], [0, 1, 0], [0, 0, 1]], eps=0) == np.inf
+    with pytest.warns(FutureWarning):
+        assert log_loss([0, 1, 2], [[1, 0, 0], [0, 1, 0], [0, 0, 1]], eps=0) == 0
+    with pytest.warns(FutureWarning):
+        assert (
+            log_loss([0, 1, 2], [[0, 0.5, 0.5], [0, 1, 0], [0, 0, 1]], eps=0) == np.inf
+        )
 
     # raise error if number of classes are not equal.
     y_true = [1, 0, 2]
@@ -2500,7 +2510,8 @@ def test_log_loss():
     # case when y_true is a string array object
     y_true = ["ham", "spam", "spam", "ham"]
     y_pred = [[0.2, 0.7], [0.6, 0.5], [0.4, 0.1], [0.7, 0.2]]
-    loss = log_loss(y_true, y_pred)
+    with pytest.warns(UserWarning, match=user_warning_msg):
+        loss = log_loss(y_true, y_pred)
     assert_almost_equal(loss, 1.0383217, decimal=6)
 
     # test labels option
@@ -2528,7 +2539,8 @@ def test_log_loss():
     # ensure labels work when len(np.unique(y_true)) != y_pred.shape[1]
     y_true = [1, 2, 2]
     y_score2 = [[0.2, 0.7, 0.3], [0.6, 0.5, 0.3], [0.3, 0.9, 0.1]]
-    loss = log_loss(y_true, y_score2, labels=[1, 2, 3])
+    with pytest.warns(UserWarning, match=user_warning_msg):
+        loss = log_loss(y_true, y_score2, labels=[1, 2, 3])
     assert_almost_equal(loss, 1.0630345, decimal=6)
 
 
@@ -2568,7 +2580,8 @@ def test_log_loss_pandas_input():
     for TrueInputType, PredInputType in types:
         # y_pred dataframe, y_true series
         y_true, y_pred = TrueInputType(y_tr), PredInputType(y_pr)
-        loss = log_loss(y_true, y_pred)
+        with pytest.warns(UserWarning, match="y_pred values do not sum to one"):
+            loss = log_loss(y_true, y_pred)
         assert_almost_equal(loss, 1.0383217, decimal=6)
 
 
+ git diff 6adb209acd63825affc884abcd85381f148fb1b0
diff --git a/sklearn/utils/multiclass.py b/sklearn/utils/multiclass.py
index 5eaef2fde..8e98e212e 100644
--- a/sklearn/utils/multiclass.py
+++ b/sklearn/utils/multiclass.py
@@ -4,11 +4,11 @@
 """
 Multi-class / multi-label utility function
 ==========================================
-
 """
 from collections.abc import Sequence
 from itertools import chain
 import warnings
+import pandas as pd
 
 from scipy.sparse import issparse
 from scipy.sparse import dok_matrix
@@ -43,26 +43,21 @@ _FN_UNIQUE_LABELS = {
 
 def unique_labels(*ys):
     """Extract an ordered array of unique labels.
-
     We don't allow:
         - mix of multilabel and multiclass (single label) targets
         - mix of label indicator matrix and anything else,
           because there are no explicit labels)
         - mix of label indicator matrices of different sizes
         - mix of string and integer labels
-
     At the moment, we also don't allow "multiclass-multioutput" input type.
-
     Parameters
     ----------
     *ys : array-likes
         Label values.
-
     Returns
     -------
     out : ndarray of shape (n_unique_labels,)
         An ordered array of unique labels.
-
     Examples
     --------
     >>> from sklearn.utils.multiclass import unique_labels
@@ -73,9 +68,22 @@ def unique_labels(*ys):
     >>> unique_labels([1, 2, 10], [5, 11])
     array([ 1,  2,  5, 10, 11])
     """
+    import pandas as pd
+
+    def convert_nullable_dtype(y):
+        if pd.api.types.is_integer_dtype(y):
+            return y.to_numpy(dtype="int64")
+        elif pd.api.types.is_float_dtype(y):
+            return y.to_numpy(dtype="float64")
+        elif pd.api.types.is_bool_dtype(y):
+            return y.to_numpy(dtype="bool")
+        return y
+
     xp, is_array_api = get_namespace(*ys)
     if not ys:
         raise ValueError("No argument has been passed.")
+    # Convert nullable dtypes to their numpy equivalents
+    ys = [convert_nullable_dtype(y) for y in ys]
     # Check that we don't mix label format
 
     ys_types = set(type_of_target(x) for x in ys)
+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z x ']'
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1='(testbed) '
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/libglib_deactivate.sh"
PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval '. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/libglib_deactivate.sh"
PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/libglib_deactivate.sh
++++ export GSETTINGS_SCHEMA_DIR=
++++ GSETTINGS_SCHEMA_DIR=
++++ unset GSETTINGS_SCHEMA_DIR_CONDA_BACKUP
++++ '[' -z ']'
++++ unset GSETTINGS_SCHEMA_DIR
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\''
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libglib_activate.sh"'
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\''
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libglib_activate.sh"'
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_3=/opt/miniconda3
++ CONDA_PREFIX_3=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/libglib_activate.sh
+++ export GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
+++ GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
+++ export GSETTINGS_SCHEMA_DIR=/opt/miniconda3/envs/testbed/share/glib-2.0/schemas
+++ GSETTINGS_SCHEMA_DIR=/opt/miniconda3/envs/testbed/share/glib-2.0/schemas
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ python -m pip install -v --no-use-pep517 --no-build-isolation -e .
Using pip 24.0 from /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pip (python 3.9)
Obtaining file:///testbed
  Preparing metadata (setup.py): started
  Running command python setup.py egg_info
  Partial import of sklearn during the build process.
  running egg_info
  creating /tmp/pip-pip-egg-info-e_pml2ut/scikit_learn.egg-info
  writing /tmp/pip-pip-egg-info-e_pml2ut/scikit_learn.egg-info/PKG-INFO
  writing dependency_links to /tmp/pip-pip-egg-info-e_pml2ut/scikit_learn.egg-info/dependency_links.txt
  writing requirements to /tmp/pip-pip-egg-info-e_pml2ut/scikit_learn.egg-info/requires.txt
  writing top-level names to /tmp/pip-pip-egg-info-e_pml2ut/scikit_learn.egg-info/top_level.txt
  writing manifest file '/tmp/pip-pip-egg-info-e_pml2ut/scikit_learn.egg-info/SOURCES.txt'
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
  dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
  reading manifest file '/tmp/pip-pip-egg-info-e_pml2ut/scikit_learn.egg-info/SOURCES.txt'
  reading manifest template 'MANIFEST.in'
  warning: no previously-included files matching '*' found under directory 'asv_benchmarks'
  warning: no previously-included files matching '*' found under directory 'benchmarks'
  warning: no previously-included files matching '*' found under directory 'build_tools'
  warning: no previously-included files matching '*' found under directory 'maint_tools'
  warning: no previously-included files matching '*' found under directory 'benchmarks'
  warning: no previously-included files matching '*' found under directory '.binder'
  warning: no previously-included files matching '*' found under directory '.circleci'
  warning: no previously-included files found matching '.cirrus.star'
  warning: no previously-included files found matching '.codecov.yml'
  warning: no previously-included files found matching '.git-blame-ignore-revs'
  warning: no previously-included files found matching '.mailmap'
  warning: no previously-included files found matching '.pre-commit-config.yaml'
  warning: no previously-included files found matching 'azure-pipelines.yml'
  warning: no previously-included files found matching 'CODE_OF_CONDUCT.md'
  warning: no previously-included files found matching 'CONTRIBUTING.md'
  warning: no previously-included files found matching 'SECURITY.md'
  warning: no previously-included files found matching 'PULL_REQUEST_TEMPLATE.md'
  adding license file 'COPYING'
  writing manifest file '/tmp/pip-pip-egg-info-e_pml2ut/scikit_learn.egg-info/SOURCES.txt'
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: numpy>=1.17.3 in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from scikit-learn==1.3.dev0) (1.26.4)
Requirement already satisfied: scipy>=1.3.2 in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from scikit-learn==1.3.dev0) (1.13.1)
Requirement already satisfied: joblib>=1.1.1 in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from scikit-learn==1.3.dev0) (1.4.2)
Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from scikit-learn==1.3.dev0) (3.5.0)
Installing collected packages: scikit-learn
  Attempting uninstall: scikit-learn
    Found existing installation: scikit-learn 1.3.dev0
    Uninstalling scikit-learn-1.3.dev0:
      Removing file or directory /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/scikit-learn.egg-link
      Removing pth entries from /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/easy-install.pth:
      Removing entry: /testbed
      Successfully uninstalled scikit-learn-1.3.dev0
  Running setup.py develop for scikit-learn
    Running command python setup.py develop
    Partial import of sklearn during the build process.
    running develop
    /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.
    !!

            ********************************************************************************
            Please avoid running ``setup.py`` and ``easy_install``.
            Instead, use pypa/build, pypa/installer or other
            standards-based tools.

            See https://github.com/pypa/setuptools/issues/917 for details.
            ********************************************************************************

    !!
      easy_install.initialize_options(self)
    /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.
    !!

            ********************************************************************************
            Please avoid running ``setup.py`` directly.
            Instead, use pypa/build, pypa/installer or other
            standards-based tools.

            See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.
            ********************************************************************************

    !!
      self.initialize_options()
    running egg_info
    writing scikit_learn.egg-info/PKG-INFO
    writing dependency_links to scikit_learn.egg-info/dependency_links.txt
    writing requirements to scikit_learn.egg-info/requires.txt
    writing top-level names to scikit_learn.egg-info/top_level.txt
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/npy_math.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h won't be automatically included in the manifest: the path must be relative
    dependency /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h won't be automatically included in the manifest: the path must be relative
    reading manifest file 'scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    warning: no previously-included files matching '*' found under directory 'asv_benchmarks'
    warning: no previously-included files matching '*' found under directory 'benchmarks'
    warning: no previously-included files matching '*' found under directory 'build_tools'
    warning: no previously-included files matching '*' found under directory 'maint_tools'
    warning: no previously-included files matching '*' found under directory 'benchmarks'
    warning: no previously-included files matching '*' found under directory '.binder'
    warning: no previously-included files matching '*' found under directory '.circleci'
    warning: no previously-included files found matching '.cirrus.star'
    warning: no previously-included files found matching '.codecov.yml'
    warning: no previously-included files found matching '.git-blame-ignore-revs'
    warning: no previously-included files found matching '.mailmap'
    warning: no previously-included files found matching '.pre-commit-config.yaml'
    warning: no previously-included files found matching 'azure-pipelines.yml'
    warning: no previously-included files found matching 'CODE_OF_CONDUCT.md'
    warning: no previously-included files found matching 'CONTRIBUTING.md'
    warning: no previously-included files found matching 'SECURITY.md'
    warning: no previously-included files found matching 'PULL_REQUEST_TEMPLATE.md'
    adding license file 'COPYING'
    writing manifest file 'scikit_learn.egg-info/SOURCES.txt'
    running build_ext
    running build_clib
    building 'libsvm-skl' library
    building 'liblinear-skl' library
    Using newest NumPy C API for extension sklearn.__check_build._check_build
    Using newest NumPy C API for extension sklearn._isotonic
    Using newest NumPy C API for extension sklearn._loss._loss
    Using newest NumPy C API for extension sklearn.cluster._dbscan_inner
    Using newest NumPy C API for extension sklearn.cluster._hierarchical_fast
    Using newest NumPy C API for extension sklearn.cluster._k_means_common
    Using newest NumPy C API for extension sklearn.cluster._k_means_lloyd
    Using newest NumPy C API for extension sklearn.cluster._k_means_elkan
    Using newest NumPy C API for extension sklearn.cluster._k_means_minibatch
    Using newest NumPy C API for extension sklearn.datasets._svmlight_format_fast
    Using newest NumPy C API for extension sklearn.decomposition._online_lda_fast
    Using newest NumPy C API for extension sklearn.decomposition._cdnmf_fast
    Using newest NumPy C API for extension sklearn.ensemble._gradient_boosting
    Using newest NumPy C API for extension sklearn.ensemble._hist_gradient_boosting._gradient_boosting
    Using newest NumPy C API for extension sklearn.ensemble._hist_gradient_boosting.histogram
    Using newest NumPy C API for extension sklearn.ensemble._hist_gradient_boosting.splitting
    Using newest NumPy C API for extension sklearn.ensemble._hist_gradient_boosting._binning
    Using newest NumPy C API for extension sklearn.ensemble._hist_gradient_boosting._predictor
    Using newest NumPy C API for extension sklearn.ensemble._hist_gradient_boosting._bitset
    Using newest NumPy C API for extension sklearn.ensemble._hist_gradient_boosting.common
    Using newest NumPy C API for extension sklearn.ensemble._hist_gradient_boosting.utils
    Using newest NumPy C API for extension sklearn.feature_extraction._hashing_fast
    Using old NumPy C API (version 1.7) for extension sklearn.linear_model._cd_fast
    Using newest NumPy C API for extension sklearn.linear_model._sgd_fast
    Using newest NumPy C API for extension sklearn.linear_model._sag_fast
    Using newest NumPy C API for extension sklearn.manifold._utils
    Using newest NumPy C API for extension sklearn.manifold._barnes_hut_tsne
    Using newest NumPy C API for extension sklearn.metrics._pairwise_fast
    Using old NumPy C API (version 1.7) for extension sklearn.metrics._dist_metrics
    Using newest NumPy C API for extension sklearn.metrics.cluster._expected_mutual_info_fast
    Using newest NumPy C API for extension sklearn.metrics._pairwise_distances_reduction._datasets_pair
    Using newest NumPy C API for extension sklearn.metrics._pairwise_distances_reduction._middle_term_computer
    Using newest NumPy C API for extension sklearn.metrics._pairwise_distances_reduction._base
    Using newest NumPy C API for extension sklearn.metrics._pairwise_distances_reduction._argkmin
    Using newest NumPy C API for extension sklearn.metrics._pairwise_distances_reduction._radius_neighbors
    Using newest NumPy C API for extension sklearn.preprocessing._csr_polynomial_expansion
    Using newest NumPy C API for extension sklearn.neighbors._ball_tree
    Using newest NumPy C API for extension sklearn.neighbors._kd_tree
    Using newest NumPy C API for extension sklearn.neighbors._partition_nodes
    Using newest NumPy C API for extension sklearn.neighbors._quad_tree
    Using newest NumPy C API for extension sklearn.svm._newrand
    Using newest NumPy C API for extension sklearn.svm._libsvm
    Using newest NumPy C API for extension sklearn.svm._liblinear
    Using newest NumPy C API for extension sklearn.svm._libsvm_sparse
    Using newest NumPy C API for extension sklearn.tree._tree
    Using newest NumPy C API for extension sklearn.tree._splitter
    Using newest NumPy C API for extension sklearn.tree._criterion
    Using newest NumPy C API for extension sklearn.tree._utils
    Using old NumPy C API (version 1.7) for extension sklearn.utils.sparsefuncs_fast
    Using newest NumPy C API for extension sklearn.utils._cython_blas
    Using old NumPy C API (version 1.7) for extension sklearn.utils.arrayfuncs
    Using newest NumPy C API for extension sklearn.utils.murmurhash
    Using newest NumPy C API for extension sklearn.utils._fast_dict
    Using newest NumPy C API for extension sklearn.utils._openmp_helpers
    Using newest NumPy C API for extension sklearn.utils._seq_dataset
    Using newest NumPy C API for extension sklearn.utils._weight_vector
    Using newest NumPy C API for extension sklearn.utils._random
    Using newest NumPy C API for extension sklearn.utils._logistic_sigmoid
    Using newest NumPy C API for extension sklearn.utils._typedefs
    Using newest NumPy C API for extension sklearn.utils._heap
    Using newest NumPy C API for extension sklearn.utils._sorting
    Using newest NumPy C API for extension sklearn.utils._vector_sentinel
    Using newest NumPy C API for extension sklearn.utils._isfinite
    Creating /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/scikit-learn.egg-link (link to .)
    Adding scikit-learn 1.3.dev0 to easy-install.pth file

    Installed /testbed
Successfully installed scikit-learn-1.3.dev0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
+ git checkout 6adb209acd63825affc884abcd85381f148fb1b0 sklearn/metrics/tests/test_classification.py sklearn/preprocessing/tests/test_label.py sklearn/utils/tests/test_multiclass.py
Updated 0 paths from ce7e16a53
+ git apply -v -
Checking patch sklearn/metrics/tests/test_classification.py...
Checking patch sklearn/preprocessing/tests/test_label.py...
Checking patch sklearn/utils/tests/test_multiclass.py...
Applied patch sklearn/metrics/tests/test_classification.py cleanly.
Applied patch sklearn/preprocessing/tests/test_label.py cleanly.
Applied patch sklearn/utils/tests/test_multiclass.py cleanly.
+ pytest -rA sklearn/metrics/tests/test_classification.py sklearn/preprocessing/tests/test_label.py sklearn/utils/tests/test_multiclass.py
[1m============================= test session starts ==============================[0m
platform linux -- Python 3.9.19, pytest-7.4.4, pluggy-1.0.0
rootdir: /testbed
configfile: setup.cfg
collected 205 items

sklearn/metrics/tests/test_classification.py [31mF[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31m [ 13%]
[0m[31mF[0m[31mF[0m[31mF[0m[32m.[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[31mF[0m[32m.[0m[32m.[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[31mF[0m[31mF[0m[31mF[0m[32m.[0m[32m.[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31m [ 48%]
[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[32m.[0m[32m.[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[33ms[0m[31mF[0m[31mF[0m[32m.[0m[32m.[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[32m.[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[32m.[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[31m               [ 76%][0m
sklearn/preprocessing/tests/test_label.py [32m.[0m[32m.[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[31m [ 91%]
[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[31m                                                                     [ 93%][0m
sklearn/utils/tests/test_multiclass.py [31mF[0m[31mF[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[31mF[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[31m                    [100%][0m

=================================== FAILURES ===================================
[31m[1m_________________ test_classification_report_dictionary_output _________________[0m

    def test_classification_report_dictionary_output():
        # Test performance report with dictionary output
        iris = datasets.load_iris()
        y_true, y_pred, _ = make_prediction(dataset=iris, binary=False)
    
        # print classification report with class names
        expected_report = {
            "setosa": {
                "precision": 0.82608695652173914,
                "recall": 0.79166666666666663,
                "f1-score": 0.8085106382978724,
                "support": 24,
            },
            "versicolor": {
                "precision": 0.33333333333333331,
                "recall": 0.096774193548387094,
                "f1-score": 0.15000000000000002,
                "support": 31,
            },
            "virginica": {
                "precision": 0.41860465116279072,
                "recall": 0.90000000000000002,
                "f1-score": 0.57142857142857151,
                "support": 20,
            },
            "macro avg": {
                "f1-score": 0.5099797365754813,
                "precision": 0.5260083136726211,
                "recall": 0.596146953405018,
                "support": 75,
            },
            "accuracy": 0.5333333333333333,
            "weighted avg": {
                "f1-score": 0.47310435663627154,
                "precision": 0.5137535108414785,
                "recall": 0.5333333333333333,
                "support": 75,
            },
        }
    
>       report = classification_report(
            y_true,
            y_pred,
            labels=np.arange(len(iris.target_names)),
            target_names=iris.target_names,
            output_dict=True,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2377: in classification_report
    not labels_given or (set(labels) == set(unique_labels(y_true, y_pred)))
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([2, 2, 0, 2, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 2, 2, 1, 0, 2, 1,
       2, 2, 0, 1, 0, 2, 1, 0, 1, 0, 1, 1, 0,...1, 2, 0, 1,
       0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 0, 1, 0, 2, 2, 0, 1,
       1, 1, 1, 0, 2, 0, 1, 2, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m______________ test_classification_report_output_dict_empty_input ______________[0m

    def test_classification_report_output_dict_empty_input():
>       report = classification_report(y_true=[], y_pred=[], output_dict=True)

[1m[31msklearn/metrics/tests/test_classification.py[0m:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2369: in classification_report
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([], dtype=float64)

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m____________________ test_precision_recall_f1_score_binary _____________________[0m

    def test_precision_recall_f1_score_binary():
        # Test Precision Recall and F1 Score for binary classification task
        y_true, y_pred, _ = make_prediction(binary=True)
    
        # detailed measures for each class
>       p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=None)

[1m[31msklearn/metrics/tests/test_classification.py[0m:235: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,
       0, 0, 1, 1, 1, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________________ test_precision_recall_f_binary_single_class __________________[0m

    @ignore_warnings
    def test_precision_recall_f_binary_single_class():
        # Test precision, recall and F-scores behave with a single positive or
        # negative class
        # Such a case may occur with non-stratified cross-validation
>       assert 1.0 == precision_score([1, 1], [1, 1])

[1m[31msklearn/metrics/tests/test_classification.py[0m:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2002: in precision_score
    p, _, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_____________________ test_precision_recall_f_extra_labels _____________________[0m

    @ignore_warnings
    def test_precision_recall_f_extra_labels():
        # Test handling of explicit additional (not in input) labels to PRF
        y_true = [1, 3, 3, 2]
        y_pred = [1, 1, 3, 2]
        y_true_bin = label_binarize(y_true, classes=np.arange(5))
        y_pred_bin = label_binarize(y_pred, classes=np.arange(5))
        data = [(y_true, y_pred), (y_true_bin, y_pred_bin)]
    
        for i, (y_true, y_pred) in enumerate(data):
            # No average: zeros in array
>           actual = recall_score(y_true, y_pred, labels=[0, 1, 2, 3, 4], average=None)

[1m[31msklearn/metrics/tests/test_classification.py[0m:294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2146: in recall_score
    _, r, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1, 3, 3, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m____________________ test_precision_recall_f_ignored_labels ____________________[0m

    @ignore_warnings
    def test_precision_recall_f_ignored_labels():
        # Test a subset of labels may be requested for PRF
        y_true = [1, 1, 2, 3]
        y_pred = [1, 3, 3, 3]
        y_true_bin = label_binarize(y_true, classes=np.arange(5))
        y_pred_bin = label_binarize(y_pred, classes=np.arange(5))
        data = [(y_true, y_pred), (y_true_bin, y_pred_bin)]
    
        for i, (y_true, y_pred) in enumerate(data):
            recall_13 = partial(recall_score, y_true, y_pred, labels=[1, 3])
            recall_all = partial(recall_score, y_true, y_pred, labels=None)
    
>           assert_array_almost_equal([0.5, 1.0], recall_13(average=None))

[1m[31msklearn/metrics/tests/test_classification.py[0m:342: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2146: in recall_score
    _, r, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1, 1, 2, 3])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________________ test_precision_recall_fscore_support_errors __________________[0m

    @ignore_warnings
    def test_precision_recall_fscore_support_errors():
        y_true, y_pred, _ = make_prediction(binary=True)
    
        # Bad beta
        with pytest.raises(ValueError):
            precision_recall_fscore_support(y_true, y_pred, beta=-0.1)
    
        # Bad pos_label
        with pytest.raises(ValueError):
>           precision_recall_fscore_support(y_true, y_pred, pos_label=2, average="binary")

[1m[31msklearn/metrics/tests/test_classification.py[0m:399: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,
       0, 0, 1, 1, 1, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m___________________ test_precision_recall_f_unused_pos_label ___________________[0m

    def test_precision_recall_f_unused_pos_label():
        # Check warning that pos_label unused when set to non-default value
        # but average != 'binary'; even if data is binary.
    
        msg = (
            r"Note that pos_label \(set to 2\) is "
            r"ignored when average != 'binary' \(got 'macro'\). You "
            r"may use labels=\[pos_label\] to specify a single "
            "positive class."
        )
        with pytest.warns(UserWarning, match=msg):
>           precision_recall_fscore_support(
                [1, 2, 1], [1, 2, 2], pos_label=2, average="macro"
            )

[1m[31msklearn/metrics/tests/test_classification.py[0m:417: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1, 2, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________________________ test_confusion_matrix_binary _________________________[0m

    def test_confusion_matrix_binary():
        # Test confusion matrix - binary classification case
        y_true, y_pred, _ = make_prediction(binary=True)
    
        def test(y_true, y_pred):
            cm = confusion_matrix(y_true, y_pred)
            assert_array_equal(cm, [[22, 3], [8, 17]])
    
            tp, fp, fn, tn = cm.flatten()
            num = tp * tn - fp * fn
            den = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))
    
            true_mcc = 0 if den == 0 else num / den
            mcc = matthews_corrcoef(y_true, y_pred)
            assert_array_almost_equal(mcc, true_mcc, decimal=2)
            assert_array_almost_equal(mcc, 0.57, decimal=2)
    
>       test(y_true, y_pred)

[1m[31msklearn/metrics/tests/test_classification.py[0m:439: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/tests/test_classification.py[0m:427: in test
    cm = confusion_matrix(y_true, y_pred)
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,
       0, 0, 1, 1, 1, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m___________________ test_multilabel_confusion_matrix_binary ____________________[0m

    def test_multilabel_confusion_matrix_binary():
        # Test multilabel confusion matrix - binary classification case
        y_true, y_pred, _ = make_prediction(binary=True)
    
        def test(y_true, y_pred):
            cm = multilabel_confusion_matrix(y_true, y_pred)
            assert_array_equal(cm, [[[17, 8], [3, 22]], [[22, 3], [8, 17]]])
    
>       test(y_true, y_pred)

[1m[31msklearn/metrics/tests/test_classification.py[0m:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/tests/test_classification.py[0m:448: in test
    cm = multilabel_confusion_matrix(y_true, y_pred)
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:513: in multilabel_confusion_matrix
    present_labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,
       0, 0, 1, 1, 1, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________________ test_multilabel_confusion_matrix_multiclass __________________[0m

    def test_multilabel_confusion_matrix_multiclass():
        # Test multilabel confusion matrix - multi-class case
        y_true, y_pred, _ = make_prediction(binary=False)
    
        def test(y_true, y_pred, string_type=False):
            # compute confusion matrix with default labels introspection
            cm = multilabel_confusion_matrix(y_true, y_pred)
            assert_array_equal(
                cm, [[[47, 4], [5, 19]], [[38, 6], [28, 3]], [[30, 25], [2, 18]]]
            )
    
            # compute confusion matrix with explicit label ordering
            labels = ["0", "2", "1"] if string_type else [0, 2, 1]
            cm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)
            assert_array_equal(
                cm, [[[47, 4], [5, 19]], [[30, 25], [2, 18]], [[38, 6], [28, 3]]]
            )
    
            # compute confusion matrix with super set of present labels
            labels = ["0", "2", "1", "3"] if string_type else [0, 2, 1, 3]
            cm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)
            assert_array_equal(
                cm,
                [
                    [[47, 4], [5, 19]],
                    [[30, 25], [2, 18]],
                    [[38, 6], [28, 3]],
                    [[75, 0], [0, 0]],
                ],
            )
    
>       test(y_true, y_pred)

[1m[31msklearn/metrics/tests/test_classification.py[0m:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/tests/test_classification.py[0m:461: in test
    cm = multilabel_confusion_matrix(y_true, y_pred)
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:513: in multilabel_confusion_matrix
    present_labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([2, 2, 0, 2, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 2, 2, 1, 0, 2, 1,
       2, 2, 0, 1, 0, 2, 1, 0, 1, 0, 1, 1, 0,...1, 2, 0, 1,
       0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 0, 1, 0, 2, 2, 0, 1,
       1, 1, 1, 0, 2, 0, 1, 2, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________________ test_multilabel_confusion_matrix_multilabel __________________[0m

    def test_multilabel_confusion_matrix_multilabel():
        # Test multilabel confusion matrix - multilabel-indicator case
        from scipy.sparse import csc_matrix, csr_matrix
    
        y_true = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 0]])
        y_pred = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])
        y_true_csr = csr_matrix(y_true)
        y_pred_csr = csr_matrix(y_pred)
        y_true_csc = csc_matrix(y_true)
        y_pred_csc = csc_matrix(y_pred)
    
        # cross test different types
        sample_weight = np.array([2, 1, 3])
        real_cm = [[[1, 0], [1, 1]], [[1, 0], [1, 1]], [[0, 2], [1, 0]]]
        trues = [y_true, y_true_csr, y_true_csc]
        preds = [y_pred, y_pred_csr, y_pred_csc]
    
        for y_true_tmp in trues:
            for y_pred_tmp in preds:
>               cm = multilabel_confusion_matrix(y_true_tmp, y_pred_tmp)

[1m[31msklearn/metrics/tests/test_classification.py[0m:509: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:513: in multilabel_confusion_matrix
    present_labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <3x3 sparse matrix of type '<class 'numpy.int64'>'
	with 5 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m___________________ test_multilabel_confusion_matrix_errors ____________________[0m

    def test_multilabel_confusion_matrix_errors():
        y_true = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 0]])
        y_pred = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])
    
        # Bad sample_weight
        with pytest.raises(ValueError, match="inconsistent numbers of samples"):
            multilabel_confusion_matrix(y_true, y_pred, sample_weight=[1, 2])
        with pytest.raises(ValueError, match="should be a 1d array"):
            multilabel_confusion_matrix(
                y_true, y_pred, sample_weight=[[1, 2, 3], [2, 3, 4], [3, 4, 5]]
            )
    
        # Bad labels
        err_msg = r"All labels must be in \[0, n labels\)"
        with pytest.raises(ValueError, match=err_msg):
>           multilabel_confusion_matrix(y_true, y_pred, labels=[-1])

[1m[31msklearn/metrics/tests/test_classification.py[0m:546: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:513: in multilabel_confusion_matrix
    present_labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <3x3 sparse matrix of type '<class 'numpy.int64'>'
	with 5 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_____________ test_confusion_matrix_normalize[true-f-0.333333333] ______________[0m

normalize = 'true', cm_dtype = 'f', expected_results = 0.333333333

    @pytest.mark.parametrize(
        "normalize, cm_dtype, expected_results",
        [
            ("true", "f", 0.333333333),
            ("pred", "f", 0.333333333),
            ("all", "f", 0.1111111111),
            (None, "i", 2),
        ],
    )
    def test_confusion_matrix_normalize(normalize, cm_dtype, expected_results):
        y_test = [0, 1, 2] * 6
        y_pred = list(chain(*permutations([0, 1, 2])))
>       cm = confusion_matrix(y_test, y_pred, normalize=normalize)

[1m[31msklearn/metrics/tests/test_classification.py[0m:573: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_____________ test_confusion_matrix_normalize[pred-f-0.333333333] ______________[0m

normalize = 'pred', cm_dtype = 'f', expected_results = 0.333333333

    @pytest.mark.parametrize(
        "normalize, cm_dtype, expected_results",
        [
            ("true", "f", 0.333333333),
            ("pred", "f", 0.333333333),
            ("all", "f", 0.1111111111),
            (None, "i", 2),
        ],
    )
    def test_confusion_matrix_normalize(normalize, cm_dtype, expected_results):
        y_test = [0, 1, 2] * 6
        y_pred = list(chain(*permutations([0, 1, 2])))
>       cm = confusion_matrix(y_test, y_pred, normalize=normalize)

[1m[31msklearn/metrics/tests/test_classification.py[0m:573: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_____________ test_confusion_matrix_normalize[all-f-0.1111111111] ______________[0m

normalize = 'all', cm_dtype = 'f', expected_results = 0.1111111111

    @pytest.mark.parametrize(
        "normalize, cm_dtype, expected_results",
        [
            ("true", "f", 0.333333333),
            ("pred", "f", 0.333333333),
            ("all", "f", 0.1111111111),
            (None, "i", 2),
        ],
    )
    def test_confusion_matrix_normalize(normalize, cm_dtype, expected_results):
        y_test = [0, 1, 2] * 6
        y_pred = list(chain(*permutations([0, 1, 2])))
>       cm = confusion_matrix(y_test, y_pred, normalize=normalize)

[1m[31msklearn/metrics/tests/test_classification.py[0m:573: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m__________________ test_confusion_matrix_normalize[None-i-2] ___________________[0m

normalize = None, cm_dtype = 'i', expected_results = 2

    @pytest.mark.parametrize(
        "normalize, cm_dtype, expected_results",
        [
            ("true", "f", 0.333333333),
            ("pred", "f", 0.333333333),
            ("all", "f", 0.1111111111),
            (None, "i", 2),
        ],
    )
    def test_confusion_matrix_normalize(normalize, cm_dtype, expected_results):
        y_test = [0, 1, 2] * 6
        y_pred = list(chain(*permutations([0, 1, 2])))
>       cm = confusion_matrix(y_test, y_pred, normalize=normalize)

[1m[31msklearn/metrics/tests/test_classification.py[0m:573: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________________ test_confusion_matrix_normalize_single_class _________________[0m

    def test_confusion_matrix_normalize_single_class():
        y_test = [0, 0, 0, 0, 1, 1, 1, 1]
        y_pred = [0, 0, 0, 0, 0, 0, 0, 0]
    
>       cm_true = confusion_matrix(y_test, y_pred, normalize="true")

[1m[31msklearn/metrics/tests/test_classification.py[0m:582: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 0, 0, 1, 1, 1, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_ test_likelihood_ratios_warnings[params0-samples of only one class were seen during testing] _[0m

params = {'y_pred': array([0, 0, 0, 0, 0, 0]), 'y_true': array([0, 0, 0, 0, 0, 0])}
warn_msg = 'samples of only one class were seen during testing'

    @pytest.mark.parametrize(
        "params, warn_msg",
        [
            # When y_test contains one class only and y_test==y_pred, LR+ is undefined
            (
                {
                    "y_true": np.array([0, 0, 0, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 0, 0, 0]),
                },
                "samples of only one class were seen during testing",
            ),
            # When `fp == 0` and `tp != 0`, LR+ is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([1, 1, 1, 0, 0, 0]),
                },
                "positive_likelihood_ratio ill-defined and being set to nan",
            ),
            # When `fp == 0` and `tp == 0`, LR+ is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 0, 0, 0]),
                },
                "no samples predicted for the positive class",
            ),
            # When `tn == 0`, LR- is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 1, 1, 1]),
                },
                "negative_likelihood_ratio ill-defined and being set to nan",
            ),
            # When `tp + fn == 0` both ratios are undefined
            (
                {
                    "y_true": np.array([0, 0, 0, 0, 0, 0]),
                    "y_pred": np.array([1, 1, 1, 0, 0, 0]),
                },
                "no samples of the positive class were present in the testing set",
            ),
        ],
    )
    def test_likelihood_ratios_warnings(params, warn_msg):
        # likelihood_ratios must raise warnings when at
        # least one of the ratios is ill-defined.
    
        with pytest.warns(UserWarning, match=warn_msg):
>           class_likelihood_ratios(**params)

[1m[31msklearn/metrics/tests/test_classification.py[0m:647: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1820: in class_likelihood_ratios
    cm = confusion_matrix(
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 0, 0, 0, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_ test_likelihood_ratios_warnings[params1-positive_likelihood_ratio ill-defined and being set to nan] _[0m

params = {'y_pred': array([1, 1, 1, 0, 0, 0]), 'y_true': array([1, 1, 1, 0, 0, 0])}
warn_msg = 'positive_likelihood_ratio ill-defined and being set to nan'

    @pytest.mark.parametrize(
        "params, warn_msg",
        [
            # When y_test contains one class only and y_test==y_pred, LR+ is undefined
            (
                {
                    "y_true": np.array([0, 0, 0, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 0, 0, 0]),
                },
                "samples of only one class were seen during testing",
            ),
            # When `fp == 0` and `tp != 0`, LR+ is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([1, 1, 1, 0, 0, 0]),
                },
                "positive_likelihood_ratio ill-defined and being set to nan",
            ),
            # When `fp == 0` and `tp == 0`, LR+ is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 0, 0, 0]),
                },
                "no samples predicted for the positive class",
            ),
            # When `tn == 0`, LR- is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 1, 1, 1]),
                },
                "negative_likelihood_ratio ill-defined and being set to nan",
            ),
            # When `tp + fn == 0` both ratios are undefined
            (
                {
                    "y_true": np.array([0, 0, 0, 0, 0, 0]),
                    "y_pred": np.array([1, 1, 1, 0, 0, 0]),
                },
                "no samples of the positive class were present in the testing set",
            ),
        ],
    )
    def test_likelihood_ratios_warnings(params, warn_msg):
        # likelihood_ratios must raise warnings when at
        # least one of the ratios is ill-defined.
    
        with pytest.warns(UserWarning, match=warn_msg):
>           class_likelihood_ratios(**params)

[1m[31msklearn/metrics/tests/test_classification.py[0m:647: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1820: in class_likelihood_ratios
    cm = confusion_matrix(
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1, 1, 1, 0, 0, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_ test_likelihood_ratios_warnings[params2-no samples predicted for the positive class] _[0m

params = {'y_pred': array([0, 0, 0, 0, 0, 0]), 'y_true': array([1, 1, 1, 0, 0, 0])}
warn_msg = 'no samples predicted for the positive class'

    @pytest.mark.parametrize(
        "params, warn_msg",
        [
            # When y_test contains one class only and y_test==y_pred, LR+ is undefined
            (
                {
                    "y_true": np.array([0, 0, 0, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 0, 0, 0]),
                },
                "samples of only one class were seen during testing",
            ),
            # When `fp == 0` and `tp != 0`, LR+ is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([1, 1, 1, 0, 0, 0]),
                },
                "positive_likelihood_ratio ill-defined and being set to nan",
            ),
            # When `fp == 0` and `tp == 0`, LR+ is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 0, 0, 0]),
                },
                "no samples predicted for the positive class",
            ),
            # When `tn == 0`, LR- is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 1, 1, 1]),
                },
                "negative_likelihood_ratio ill-defined and being set to nan",
            ),
            # When `tp + fn == 0` both ratios are undefined
            (
                {
                    "y_true": np.array([0, 0, 0, 0, 0, 0]),
                    "y_pred": np.array([1, 1, 1, 0, 0, 0]),
                },
                "no samples of the positive class were present in the testing set",
            ),
        ],
    )
    def test_likelihood_ratios_warnings(params, warn_msg):
        # likelihood_ratios must raise warnings when at
        # least one of the ratios is ill-defined.
    
        with pytest.warns(UserWarning, match=warn_msg):
>           class_likelihood_ratios(**params)

[1m[31msklearn/metrics/tests/test_classification.py[0m:647: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1820: in class_likelihood_ratios
    cm = confusion_matrix(
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1, 1, 1, 0, 0, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_ test_likelihood_ratios_warnings[params3-negative_likelihood_ratio ill-defined and being set to nan] _[0m

params = {'y_pred': array([0, 0, 0, 1, 1, 1]), 'y_true': array([1, 1, 1, 0, 0, 0])}
warn_msg = 'negative_likelihood_ratio ill-defined and being set to nan'

    @pytest.mark.parametrize(
        "params, warn_msg",
        [
            # When y_test contains one class only and y_test==y_pred, LR+ is undefined
            (
                {
                    "y_true": np.array([0, 0, 0, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 0, 0, 0]),
                },
                "samples of only one class were seen during testing",
            ),
            # When `fp == 0` and `tp != 0`, LR+ is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([1, 1, 1, 0, 0, 0]),
                },
                "positive_likelihood_ratio ill-defined and being set to nan",
            ),
            # When `fp == 0` and `tp == 0`, LR+ is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 0, 0, 0]),
                },
                "no samples predicted for the positive class",
            ),
            # When `tn == 0`, LR- is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 1, 1, 1]),
                },
                "negative_likelihood_ratio ill-defined and being set to nan",
            ),
            # When `tp + fn == 0` both ratios are undefined
            (
                {
                    "y_true": np.array([0, 0, 0, 0, 0, 0]),
                    "y_pred": np.array([1, 1, 1, 0, 0, 0]),
                },
                "no samples of the positive class were present in the testing set",
            ),
        ],
    )
    def test_likelihood_ratios_warnings(params, warn_msg):
        # likelihood_ratios must raise warnings when at
        # least one of the ratios is ill-defined.
    
        with pytest.warns(UserWarning, match=warn_msg):
>           class_likelihood_ratios(**params)

[1m[31msklearn/metrics/tests/test_classification.py[0m:647: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1820: in class_likelihood_ratios
    cm = confusion_matrix(
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1, 1, 1, 0, 0, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_ test_likelihood_ratios_warnings[params4-no samples of the positive class were present in the testing set] _[0m

params = {'y_pred': array([1, 1, 1, 0, 0, 0]), 'y_true': array([0, 0, 0, 0, 0, 0])}
warn_msg = 'no samples of the positive class were present in the testing set'

    @pytest.mark.parametrize(
        "params, warn_msg",
        [
            # When y_test contains one class only and y_test==y_pred, LR+ is undefined
            (
                {
                    "y_true": np.array([0, 0, 0, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 0, 0, 0]),
                },
                "samples of only one class were seen during testing",
            ),
            # When `fp == 0` and `tp != 0`, LR+ is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([1, 1, 1, 0, 0, 0]),
                },
                "positive_likelihood_ratio ill-defined and being set to nan",
            ),
            # When `fp == 0` and `tp == 0`, LR+ is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 0, 0, 0]),
                },
                "no samples predicted for the positive class",
            ),
            # When `tn == 0`, LR- is undefined
            (
                {
                    "y_true": np.array([1, 1, 1, 0, 0, 0]),
                    "y_pred": np.array([0, 0, 0, 1, 1, 1]),
                },
                "negative_likelihood_ratio ill-defined and being set to nan",
            ),
            # When `tp + fn == 0` both ratios are undefined
            (
                {
                    "y_true": np.array([0, 0, 0, 0, 0, 0]),
                    "y_pred": np.array([1, 1, 1, 0, 0, 0]),
                },
                "no samples of the positive class were present in the testing set",
            ),
        ],
    )
    def test_likelihood_ratios_warnings(params, warn_msg):
        # likelihood_ratios must raise warnings when at
        # least one of the ratios is ill-defined.
    
        with pytest.warns(UserWarning, match=warn_msg):
>           class_likelihood_ratios(**params)

[1m[31msklearn/metrics/tests/test_classification.py[0m:647: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1820: in class_likelihood_ratios
    cm = confusion_matrix(
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 0, 0, 0, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m____________________________ test_likelihood_ratios ____________________________[0m

    def test_likelihood_ratios():
        # Build confusion matrix with tn=9, fp=8, fn=1, tp=2,
        # sensitivity=2/3, specificity=9/17, prevalence=3/20,
        # LR+=34/24, LR-=17/27
        y_true = np.array([1] * 3 + [0] * 17)
        y_pred = np.array([1] * 2 + [0] * 10 + [1] * 8)
    
>       pos, neg = class_likelihood_ratios(y_true, y_pred)

[1m[31msklearn/metrics/tests/test_classification.py[0m:677: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1820: in class_likelihood_ratios
    cm = confusion_matrix(
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_______________________________ test_cohen_kappa _______________________________[0m

    def test_cohen_kappa():
        # These label vectors reproduce the contingency matrix from Artstein and
        # Poesio (2008), Table 1: np.array([[20, 20], [10, 50]]).
        y1 = np.array([0] * 40 + [1] * 60)
        y2 = np.array([0] * 20 + [1] * 20 + [0] * 10 + [1] * 50)
>       kappa = cohen_kappa_score(y1, y2)

[1m[31msklearn/metrics/tests/test_classification.py[0m:700: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:679: in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m__________________________ test_matthews_corrcoef_nan __________________________[0m

    def test_matthews_corrcoef_nan():
>       assert matthews_corrcoef([0], [1]) == 0.0

[1m[31msklearn/metrics/tests/test_classification.py[0m:727: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:944: in matthews_corrcoef
    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________________ test_matthews_corrcoef_against_numpy_corrcoef _________________[0m

    def test_matthews_corrcoef_against_numpy_corrcoef():
        rng = np.random.RandomState(0)
        y_true = rng.randint(0, 2, size=20)
        y_pred = rng.randint(0, 2, size=20)
    
        assert_almost_equal(
>           matthews_corrcoef(y_true, y_pred), np.corrcoef(y_true, y_pred)[0, 1], 10
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:737: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:944: in matthews_corrcoef
    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m____________________ test_matthews_corrcoef_against_jurman _____________________[0m

    def test_matthews_corrcoef_against_jurman():
        # Check that the multiclass matthews_corrcoef agrees with the definition
        # presented in Jurman, Riccadonna, Furlanello, (2012). A Comparison of MCC
        # and CEN Error Measures in MultiClass Prediction
        rng = np.random.RandomState(0)
        y_true = rng.randint(0, 2, size=20)
        y_pred = rng.randint(0, 2, size=20)
        sample_weight = rng.rand(20)
    
>       C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)

[1m[31msklearn/metrics/tests/test_classification.py[0m:750: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m____________________________ test_matthews_corrcoef ____________________________[0m

    def test_matthews_corrcoef():
        rng = np.random.RandomState(0)
        y_true = ["a" if i == 0 else "b" for i in rng.randint(0, 2, size=20)]
    
        # corrcoef of same vectors must be 1
>       assert_almost_equal(matthews_corrcoef(y_true, y_true), 1.0)

[1m[31msklearn/metrics/tests/test_classification.py[0m:785: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:944: in matthews_corrcoef
    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m______________________ test_matthews_corrcoef_multiclass _______________________[0m

    def test_matthews_corrcoef_multiclass():
        rng = np.random.RandomState(0)
        ord_a = ord("a")
        n_classes = 4
        y_true = [chr(ord_a + i) for i in rng.randint(0, n_classes, size=20)]
    
        # corrcoef of same vectors must be 1
>       assert_almost_equal(matthews_corrcoef(y_true, y_true), 1.0)

[1m[31msklearn/metrics/tests/test_classification.py[0m:822: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:944: in matthews_corrcoef
    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 3, 1, 0, 3, 3, 3, 3, 1, 3, 1, 2, 0, 3, 2, 0, 0, 0, 2, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_____________________ test_matthews_corrcoef_overflow[100] _____________________[0m

n_points = 100

    @pytest.mark.parametrize("n_points", [100, 10000])
    def test_matthews_corrcoef_overflow(n_points):
        # https://github.com/scikit-learn/scikit-learn/issues/9622
        rng = np.random.RandomState(20170906)
    
        def mcc_safe(y_true, y_pred):
            conf_matrix = confusion_matrix(y_true, y_pred)
            true_pos = conf_matrix[1, 1]
            false_pos = conf_matrix[1, 0]
            false_neg = conf_matrix[0, 1]
            n_points = len(y_true)
            pos_rate = (true_pos + false_neg) / n_points
            activity = (true_pos + false_pos) / n_points
            mcc_numerator = true_pos / n_points - pos_rate * activity
            mcc_denominator = activity * pos_rate * (1 - activity) * (1 - pos_rate)
            return mcc_numerator / np.sqrt(mcc_denominator)
    
        def random_ys(n_points):  # binary
            x_true = rng.random_sample(n_points)
            x_pred = x_true + 0.2 * (rng.random_sample(n_points) - 0.5)
            y_true = x_true > 0.5
            y_pred = x_pred > 0.5
            return y_true, y_pred
    
        arr = np.repeat([0.0, 1.0], n_points)  # binary
>       assert_almost_equal(matthews_corrcoef(arr, arr), 1.0)

[1m[31msklearn/metrics/tests/test_classification.py[0m:896: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:944: in matthews_corrcoef
    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m____________________ test_matthews_corrcoef_overflow[10000] ____________________[0m

n_points = 10000

    @pytest.mark.parametrize("n_points", [100, 10000])
    def test_matthews_corrcoef_overflow(n_points):
        # https://github.com/scikit-learn/scikit-learn/issues/9622
        rng = np.random.RandomState(20170906)
    
        def mcc_safe(y_true, y_pred):
            conf_matrix = confusion_matrix(y_true, y_pred)
            true_pos = conf_matrix[1, 1]
            false_pos = conf_matrix[1, 0]
            false_neg = conf_matrix[0, 1]
            n_points = len(y_true)
            pos_rate = (true_pos + false_neg) / n_points
            activity = (true_pos + false_pos) / n_points
            mcc_numerator = true_pos / n_points - pos_rate * activity
            mcc_denominator = activity * pos_rate * (1 - activity) * (1 - pos_rate)
            return mcc_numerator / np.sqrt(mcc_denominator)
    
        def random_ys(n_points):  # binary
            x_true = rng.random_sample(n_points)
            x_pred = x_true + 0.2 * (rng.random_sample(n_points) - 0.5)
            y_true = x_true > 0.5
            y_pred = x_pred > 0.5
            return y_true, y_pred
    
        arr = np.repeat([0.0, 1.0], n_points)  # binary
>       assert_almost_equal(matthews_corrcoef(arr, arr), 1.0)

[1m[31msklearn/metrics/tests/test_classification.py[0m:896: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:944: in matthews_corrcoef
    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 0, ..., 1, 1, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m__________________ test_precision_recall_f1_score_multiclass ___________________[0m

    def test_precision_recall_f1_score_multiclass():
        # Test Precision Recall and F1 Score for multiclass classification task
        y_true, y_pred, _ = make_prediction(binary=False)
    
        # compute scores with default labels introspection
>       p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=None)

[1m[31msklearn/metrics/tests/test_classification.py[0m:910: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([2, 2, 0, 2, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 2, 2, 1, 0, 2, 1,
       2, 2, 0, 1, 0, 2, 1, 0, 1, 0, 1, 1, 0,...1, 2, 0, 1,
       0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 0, 1, 0, 2, 2, 0, 1,
       1, 1, 1, 0, 2, 0, 1, 2, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_____ test_precision_refcall_f1_score_multilabel_unordered_labels[samples] _____[0m

average = 'samples'

    @pytest.mark.parametrize("average", ["samples", "micro", "macro", "weighted", None])
    def test_precision_refcall_f1_score_multilabel_unordered_labels(average):
        # test that labels need not be sorted in the multilabel case
        y_true = np.array([[1, 1, 0, 0]])
        y_pred = np.array([[0, 0, 1, 1]])
>       p, r, f, s = precision_recall_fscore_support(
            y_true, y_pred, labels=[3, 0, 1, 2], warn_for=[], average=average
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:968: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <1x4 sparse matrix of type '<class 'numpy.int64'>'
	with 2 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m______ test_precision_refcall_f1_score_multilabel_unordered_labels[micro] ______[0m

average = 'micro'

    @pytest.mark.parametrize("average", ["samples", "micro", "macro", "weighted", None])
    def test_precision_refcall_f1_score_multilabel_unordered_labels(average):
        # test that labels need not be sorted in the multilabel case
        y_true = np.array([[1, 1, 0, 0]])
        y_pred = np.array([[0, 0, 1, 1]])
>       p, r, f, s = precision_recall_fscore_support(
            y_true, y_pred, labels=[3, 0, 1, 2], warn_for=[], average=average
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:968: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <1x4 sparse matrix of type '<class 'numpy.int64'>'
	with 2 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m______ test_precision_refcall_f1_score_multilabel_unordered_labels[macro] ______[0m

average = 'macro'

    @pytest.mark.parametrize("average", ["samples", "micro", "macro", "weighted", None])
    def test_precision_refcall_f1_score_multilabel_unordered_labels(average):
        # test that labels need not be sorted in the multilabel case
        y_true = np.array([[1, 1, 0, 0]])
        y_pred = np.array([[0, 0, 1, 1]])
>       p, r, f, s = precision_recall_fscore_support(
            y_true, y_pred, labels=[3, 0, 1, 2], warn_for=[], average=average
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:968: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <1x4 sparse matrix of type '<class 'numpy.int64'>'
	with 2 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m____ test_precision_refcall_f1_score_multilabel_unordered_labels[weighted] _____[0m

average = 'weighted'

    @pytest.mark.parametrize("average", ["samples", "micro", "macro", "weighted", None])
    def test_precision_refcall_f1_score_multilabel_unordered_labels(average):
        # test that labels need not be sorted in the multilabel case
        y_true = np.array([[1, 1, 0, 0]])
        y_pred = np.array([[0, 0, 1, 1]])
>       p, r, f, s = precision_recall_fscore_support(
            y_true, y_pred, labels=[3, 0, 1, 2], warn_for=[], average=average
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:968: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <1x4 sparse matrix of type '<class 'numpy.int64'>'
	with 2 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m______ test_precision_refcall_f1_score_multilabel_unordered_labels[None] _______[0m

average = None

    @pytest.mark.parametrize("average", ["samples", "micro", "macro", "weighted", None])
    def test_precision_refcall_f1_score_multilabel_unordered_labels(average):
        # test that labels need not be sorted in the multilabel case
        y_true = np.array([[1, 1, 0, 0]])
        y_pred = np.array([[0, 0, 1, 1]])
>       p, r, f, s = precision_recall_fscore_support(
            y_true, y_pred, labels=[3, 0, 1, 2], warn_for=[], average=average
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:968: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <1x4 sparse matrix of type '<class 'numpy.int64'>'
	with 2 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________________ test_precision_recall_f1_score_binary_averaged ________________[0m

    def test_precision_recall_f1_score_binary_averaged():
        y_true = np.array([0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1])
        y_pred = np.array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1])
    
        # compute scores with default labels introspection
>       ps, rs, fs, _ = precision_recall_fscore_support(y_true, y_pred, average=None)

[1m[31msklearn/metrics/tests/test_classification.py[0m:983: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m__________________________ test_zero_precision_recall __________________________[0m

    def test_zero_precision_recall():
        # Check that pathological cases do not bring NaNs
    
        old_error_settings = np.seterr(all="raise")
    
        try:
            y_true = np.array([0, 1, 2, 0, 1, 2])
            y_pred = np.array([2, 0, 1, 1, 2, 0])
    
>           assert_almost_equal(precision_score(y_true, y_pred, average="macro"), 0.0, 2)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1004: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2002: in precision_score
    p, _, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 2, 0, 1, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_______________ test_confusion_matrix_on_zero_length_input[None] _______________[0m

labels = None

    @pytest.mark.parametrize(
        "labels", (None, [0, 1], [0, 1, 2]), ids=["None", "binary", "multiclass"]
    )
    def test_confusion_matrix_on_zero_length_input(labels):
        expected_n_classes = len(labels) if labels else 0
        expected = np.zeros((expected_n_classes, expected_n_classes), dtype=int)
>       cm = confusion_matrix([], [], labels=labels)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1051: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([], dtype=float64)

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m_________________________ test_confusion_matrix_dtype __________________________[0m

    def test_confusion_matrix_dtype():
        y = [0, 1, 1]
        weight = np.ones(len(y))
        # confusion_matrix returns int64 by default
>       cm = confusion_matrix(y, y)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1059: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________________ test_confusion_matrix_pandas_nullable[Int64] _________________[0m

dtype = 'Int64'

    @pytest.mark.parametrize("dtype", ["Int64", "Float64", "boolean"])
    def test_confusion_matrix_pandas_nullable(dtype):
        """Checks that confusion_matrix works with pandas nullable dtypes.
    
        Non-regression test for gh-25635.
        """
        pd = pytest.importorskip("pandas")
    
        y_ndarray = np.array([1, 0, 0, 1, 0, 1, 1, 0, 1])
        y_true = pd.Series(y_ndarray, dtype=dtype)
        y_predicted = pd.Series([0, 0, 1, 1, 0, 1, 1, 1, 1], dtype="int64")
    
>       output = confusion_matrix(y_true, y_predicted)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1094: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1., 0., 0., 1., 0., 1., 1., 0., 1.])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m________________ test_confusion_matrix_pandas_nullable[Float64] ________________[0m

dtype = 'Float64'

    @pytest.mark.parametrize("dtype", ["Int64", "Float64", "boolean"])
    def test_confusion_matrix_pandas_nullable(dtype):
        """Checks that confusion_matrix works with pandas nullable dtypes.
    
        Non-regression test for gh-25635.
        """
        pd = pytest.importorskip("pandas")
    
        y_ndarray = np.array([1, 0, 0, 1, 0, 1, 1, 0, 1])
        y_true = pd.Series(y_ndarray, dtype=dtype)
        y_predicted = pd.Series([0, 0, 1, 1, 0, 1, 1, 1, 1], dtype="int64")
    
>       output = confusion_matrix(y_true, y_predicted)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1094: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1., 0., 0., 1., 0., 1., 1., 0., 1.])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m________________ test_confusion_matrix_pandas_nullable[boolean] ________________[0m

dtype = 'boolean'

    @pytest.mark.parametrize("dtype", ["Int64", "Float64", "boolean"])
    def test_confusion_matrix_pandas_nullable(dtype):
        """Checks that confusion_matrix works with pandas nullable dtypes.
    
        Non-regression test for gh-25635.
        """
        pd = pytest.importorskip("pandas")
    
        y_ndarray = np.array([1, 0, 0, 1, 0, 1, 1, 0, 1])
        y_true = pd.Series(y_ndarray, dtype=dtype)
        y_predicted = pd.Series([0, 0, 1, 1, 0, 1, 1, 1, 1], dtype="int64")
    
>       output = confusion_matrix(y_true, y_predicted)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1094: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1., 0., 0., 1., 0., 1., 1., 0., 1.])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m____________________ test_classification_report_multiclass _____________________[0m

    def test_classification_report_multiclass():
        # Test performance report
        iris = datasets.load_iris()
        y_true, y_pred, _ = make_prediction(dataset=iris, binary=False)
    
        # print classification report with class names
        expected_report = """\
                  precision    recall  f1-score   support
    
          setosa       0.83      0.79      0.81        24
      versicolor       0.33      0.10      0.15        31
       virginica       0.42      0.90      0.57        20
    
        accuracy                           0.53        75
       macro avg       0.53      0.60      0.51        75
    weighted avg       0.51      0.53      0.47        75
    """
>       report = classification_report(
            y_true,
            y_pred,
            labels=np.arange(len(iris.target_names)),
            target_names=iris.target_names,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1117: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2377: in classification_report
    not labels_given or (set(labels) == set(unique_labels(y_true, y_pred)))
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([2, 2, 0, 2, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 2, 2, 1, 0, 2, 1,
       2, 2, 0, 1, 0, 2, 1, 0, 1, 0, 1, 1, 0,...1, 2, 0, 1,
       0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 0, 1, 0, 2, 2, 0, 1,
       1, 1, 1, 0, 2, 0, 1, 2, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________________ test_classification_report_multiclass_balanced ________________[0m

    def test_classification_report_multiclass_balanced():
        y_true, y_pred = [0, 0, 0, 1, 1, 1, 2, 2, 2], [0, 1, 2, 0, 1, 2, 0, 1, 2]
    
        expected_report = """\
                  precision    recall  f1-score   support
    
               0       0.33      0.33      0.33         3
               1       0.33      0.33      0.33         3
               2       0.33      0.33      0.33         3
    
        accuracy                           0.33         9
       macro avg       0.33      0.33      0.33         9
    weighted avg       0.33      0.33      0.33         9
    """
>       report = classification_report(y_true, y_pred)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2369: in classification_report
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 0, 1, 1, 1, 2, 2, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m__________ test_classification_report_multiclass_with_label_detection __________[0m

    def test_classification_report_multiclass_with_label_detection():
        iris = datasets.load_iris()
        y_true, y_pred, _ = make_prediction(dataset=iris, binary=False)
    
        # print classification report with label detection
        expected_report = """\
                  precision    recall  f1-score   support
    
               0       0.83      0.79      0.81        24
               1       0.33      0.10      0.15        31
               2       0.42      0.90      0.57        20
    
        accuracy                           0.53        75
       macro avg       0.53      0.60      0.51        75
    weighted avg       0.51      0.53      0.47        75
    """
>       report = classification_report(y_true, y_pred)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2369: in classification_report
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([2, 2, 0, 2, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 2, 2, 1, 0, 2, 1,
       2, 2, 0, 1, 0, 2, 1, 0, 1, 0, 1, 1, 0,...1, 2, 0, 1,
       0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 0, 1, 0, 2, 2, 0, 1,
       1, 1, 1, 0, 2, 0, 1, 2, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m______________ test_classification_report_multiclass_with_digits _______________[0m

    def test_classification_report_multiclass_with_digits():
        # Test performance report with added digits in floating point values
        iris = datasets.load_iris()
        y_true, y_pred, _ = make_prediction(dataset=iris, binary=False)
    
        # print classification report with class names
        expected_report = """\
                  precision    recall  f1-score   support
    
          setosa    0.82609   0.79167   0.80851        24
      versicolor    0.33333   0.09677   0.15000        31
       virginica    0.41860   0.90000   0.57143        20
    
        accuracy                        0.53333        75
       macro avg    0.52601   0.59615   0.50998        75
    weighted avg    0.51375   0.53333   0.47310        75
    """
>       report = classification_report(
            y_true,
            y_pred,
            labels=np.arange(len(iris.target_names)),
            target_names=iris.target_names,
            digits=5,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1181: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2377: in classification_report
    not labels_given or (set(labels) == set(unique_labels(y_true, y_pred)))
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([2, 2, 0, 2, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 2, 2, 1, 0, 2, 1,
       2, 2, 0, 1, 0, 2, 1, 0, 1, 0, 1, 1, 0,...1, 2, 0, 1,
       0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 0, 1, 0, 2, 2, 0, 1,
       1, 1, 1, 0, 2, 0, 1, 2, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________ test_classification_report_labels_target_names_unequal_length _________[0m

    def test_classification_report_labels_target_names_unequal_length():
        y_true = [0, 0, 2, 0, 0]
        y_pred = [0, 2, 2, 0, 0]
        target_names = ["class 0", "class 1", "class 2"]
    
        msg = "labels size, 2, does not match size of target_names, 3"
        with pytest.warns(UserWarning, match=msg):
>           classification_report(y_true, y_pred, labels=[0, 2], target_names=target_names)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1278: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2377: in classification_report
    not labels_given or (set(labels) == set(unique_labels(y_true, y_pred)))
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 2, 0, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_______ test_classification_report_no_labels_target_names_unequal_length _______[0m

    def test_classification_report_no_labels_target_names_unequal_length():
        y_true = [0, 0, 2, 0, 0]
        y_pred = [0, 2, 2, 0, 0]
        target_names = ["class 0", "class 1", "class 2"]
    
        err_msg = (
            "Number of classes, 2, does not "
            "match size of target_names, 3. "
            "Try specifying the labels parameter"
        )
        with pytest.raises(ValueError, match=err_msg):
>           classification_report(y_true, y_pred, target_names=target_names)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1292: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2369: in classification_report
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 2, 0, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m____________________ test_multilabel_classification_report _____________________[0m

    @ignore_warnings
    def test_multilabel_classification_report():
        n_classes = 4
        n_samples = 50
    
        _, y_true = make_multilabel_classification(
            n_features=1, n_samples=n_samples, n_classes=n_classes, random_state=0
        )
    
        _, y_pred = make_multilabel_classification(
            n_features=1, n_samples=n_samples, n_classes=n_classes, random_state=1
        )
    
        expected_report = """\
                  precision    recall  f1-score   support
    
               0       0.50      0.67      0.57        24
               1       0.51      0.74      0.61        27
               2       0.29      0.08      0.12        26
               3       0.52      0.56      0.54        27
    
       micro avg       0.50      0.51      0.50       104
       macro avg       0.45      0.51      0.46       104
    weighted avg       0.45      0.51      0.46       104
     samples avg       0.46      0.42      0.40       104
    """
    
>       report = classification_report(y_true, y_pred)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2369: in classification_report
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <50x4 sparse matrix of type '<class 'numpy.int64'>'
	with 104 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________________________ test_jaccard_score_validation _________________________[0m

    def test_jaccard_score_validation():
        y_true = np.array([0, 1, 0, 1, 1])
        y_pred = np.array([0, 1, 0, 1, 1])
        err_msg = r"pos_label=2 is not a valid label. It should be one of \[0, 1\]"
        with pytest.raises(ValueError, match=err_msg):
>           jaccard_score(y_true, y_pred, average="binary", pos_label=2)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:832: in jaccard_score
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 0, 1, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________________________ test_multilabel_jaccard_score _________________________[0m

recwarn = WarningsRecorder(record=True)

    def test_multilabel_jaccard_score(recwarn):
        # Dense label indicator matrix format
        y1 = np.array([[0, 1, 1], [1, 0, 1]])
        y2 = np.array([[0, 0, 1], [1, 0, 1]])
    
        # size(y1 \inter y2) = [1, 2]
        # size(y1 \union y2) = [2, 2]
    
>       assert jaccard_score(y1, y2, average="samples") == 0.75

[1m[31msklearn/metrics/tests/test_classification.py[0m:1408: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:832: in jaccard_score
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x3 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________________________ test_multiclass_jaccard_score _________________________[0m

recwarn = WarningsRecorder(record=True)

    def test_multiclass_jaccard_score(recwarn):
        y_true = ["ant", "ant", "cat", "cat", "ant", "cat", "bird", "bird"]
        y_pred = ["cat", "ant", "cat", "cat", "ant", "bird", "bird", "cat"]
        labels = ["ant", "bird", "cat"]
        lb = LabelBinarizer()
        lb.fit(labels)
        y_true_bin = lb.transform(y_true)
        y_pred_bin = lb.transform(y_pred)
        multi_jaccard_score = partial(jaccard_score, y_true, y_pred)
        bin_jaccard_score = partial(jaccard_score, y_true_bin, y_pred_bin)
        multi_labels_list = [
            ["ant", "bird"],
            ["ant", "cat"],
            ["cat", "bird"],
            ["ant"],
            ["bird"],
            ["cat"],
            None,
        ]
        bin_labels_list = [[0, 1], [0, 2], [2, 1], [0], [1], [2], None]
    
        # other than average='samples'/'none-samples', test everything else here
        for average in ("macro", "weighted", "micro", None):
            for m_label, b_label in zip(multi_labels_list, bin_labels_list):
                assert_almost_equal(
                    multi_jaccard_score(average=average, labels=m_label),
>                   bin_jaccard_score(average=average, labels=b_label),
                )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1503: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:832: in jaccard_score
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <8x3 sparse matrix of type '<class 'numpy.int64'>'
	with 8 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m______________________ test_average_binary_jaccard_score _______________________[0m

recwarn = WarningsRecorder(record=True)

    def test_average_binary_jaccard_score(recwarn):
        # tp=0, fp=0, fn=1, tn=0
>       assert jaccard_score([1], [0], average="binary") == 0.0

[1m[31msklearn/metrics/tests/test_classification.py[0m:1516: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:832: in jaccard_score
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m___________________ test_jaccard_score_zero_division_warning ___________________[0m

    def test_jaccard_score_zero_division_warning():
        # check that we raised a warning with default behavior if a zero division
        # happens
        y_true = np.array([[1, 0, 1], [0, 0, 0]])
        y_pred = np.array([[0, 0, 0], [0, 0, 0]])
        msg = (
            "Jaccard is ill-defined and being set to 0.0 in "
            "samples with no true or predicted labels."
            " Use `zero_division` parameter to control this behavior."
        )
        with pytest.warns(UndefinedMetricWarning, match=msg):
>           score = jaccard_score(y_true, y_pred, average="samples", zero_division="warn")

[1m[31msklearn/metrics/tests/test_classification.py[0m:1548: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:832: in jaccard_score
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x3 sparse matrix of type '<class 'numpy.int64'>'
	with 2 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_______________ test_jaccard_score_zero_division_set_value[0-0] ________________[0m

zero_division = 0, expected_score = 0

    @pytest.mark.parametrize("zero_division, expected_score", [(0, 0), (1, 0.5)])
    def test_jaccard_score_zero_division_set_value(zero_division, expected_score):
        # check that we don't issue warning by passing the zero_division parameter
        y_true = np.array([[1, 0, 1], [0, 0, 0]])
        y_pred = np.array([[0, 0, 0], [0, 0, 0]])
        with warnings.catch_warnings():
            warnings.simplefilter("error", UndefinedMetricWarning)
>           score = jaccard_score(
                y_true, y_pred, average="samples", zero_division=zero_division
            )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:832: in jaccard_score
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x3 sparse matrix of type '<class 'numpy.int64'>'
	with 2 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m______________ test_jaccard_score_zero_division_set_value[1-0.5] _______________[0m

zero_division = 1, expected_score = 0.5

    @pytest.mark.parametrize("zero_division, expected_score", [(0, 0), (1, 0.5)])
    def test_jaccard_score_zero_division_set_value(zero_division, expected_score):
        # check that we don't issue warning by passing the zero_division parameter
        y_true = np.array([[1, 0, 1], [0, 0, 0]])
        y_pred = np.array([[0, 0, 0], [0, 0, 0]])
        with warnings.catch_warnings():
            warnings.simplefilter("error", UndefinedMetricWarning)
>           score = jaccard_score(
                y_true, y_pred, average="samples", zero_division=zero_division
            )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:832: in jaccard_score
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x3 sparse matrix of type '<class 'numpy.int64'>'
	with 2 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________________ test_precision_recall_f1_score_multilabel_1 __________________[0m

    @ignore_warnings
    def test_precision_recall_f1_score_multilabel_1():
        # Test precision_recall_f1_score on a crafted multilabel example
        # First crafted example
    
        y_true = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 1]])
        y_pred = np.array([[0, 1, 0, 0], [0, 1, 0, 0], [1, 0, 1, 0]])
    
>       p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=None)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1573: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <3x4 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________________ test_precision_recall_f1_score_multilabel_2 __________________[0m

    @ignore_warnings
    def test_precision_recall_f1_score_multilabel_2():
        # Test precision_recall_f1_score on a crafted multilabel example 2
        # Second crafted example
        y_true = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 1, 1, 0]])
        y_pred = np.array([[0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 0, 0]])
    
        # tp = [ 0.  1.  0.  0.]
        # fp = [ 1.  0.  0.  2.]
        # fn = [ 1.  1.  1.  0.]
    
>       p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=None)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <3x4 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________ test_precision_recall_f1_score_with_an_empty_prediction[warn] _________[0m

zero_division = 0.0

    @ignore_warnings
    @pytest.mark.parametrize("zero_division", ["warn", 0, 1])
    def test_precision_recall_f1_score_with_an_empty_prediction(zero_division):
        y_true = np.array([[0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 1, 0]])
        y_pred = np.array([[0, 0, 0, 0], [0, 0, 0, 1], [0, 1, 1, 0]])
    
        # true_pos = [ 0.  1.  1.  0.]
        # false_pos = [ 0.  0.  0.  1.]
        # false_neg = [ 1.  1.  0.  0.]
        zero_division = 1.0 if zero_division == 1.0 else 0.0
>       p, r, f, s = precision_recall_fscore_support(
            y_true, y_pred, average=None, zero_division=zero_division
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <3x4 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m__________ test_precision_recall_f1_score_with_an_empty_prediction[0] __________[0m

zero_division = 0.0

    @ignore_warnings
    @pytest.mark.parametrize("zero_division", ["warn", 0, 1])
    def test_precision_recall_f1_score_with_an_empty_prediction(zero_division):
        y_true = np.array([[0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 1, 0]])
        y_pred = np.array([[0, 0, 0, 0], [0, 0, 0, 1], [0, 1, 1, 0]])
    
        # true_pos = [ 0.  1.  1.  0.]
        # false_pos = [ 0.  0.  0.  1.]
        # false_neg = [ 1.  1.  0.  0.]
        zero_division = 1.0 if zero_division == 1.0 else 0.0
>       p, r, f, s = precision_recall_fscore_support(
            y_true, y_pred, average=None, zero_division=zero_division
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <3x4 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m__________ test_precision_recall_f1_score_with_an_empty_prediction[1] __________[0m

zero_division = 1.0

    @ignore_warnings
    @pytest.mark.parametrize("zero_division", ["warn", 0, 1])
    def test_precision_recall_f1_score_with_an_empty_prediction(zero_division):
        y_true = np.array([[0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 1, 0]])
        y_pred = np.array([[0, 0, 0, 0], [0, 0, 0, 1], [0, 1, 1, 0]])
    
        # true_pos = [ 0.  1.  1.  0.]
        # false_pos = [ 0.  0.  0.  1.]
        # false_neg = [ 1.  1.  0.  0.]
        zero_division = 1.0 if zero_division == 1.0 else 0.0
>       p, r, f, s = precision_recall_fscore_support(
            y_true, y_pred, average=None, zero_division=zero_division
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <3x4 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________________ test_precision_recall_f1_no_labels[0-macro-1] _________________[0m

beta = 1, average = 'macro', zero_division = 0

    @pytest.mark.parametrize("beta", [1])
    @pytest.mark.parametrize("average", ["macro", "micro", "weighted", "samples"])
    @pytest.mark.parametrize("zero_division", [0, 1])
    def test_precision_recall_f1_no_labels(beta, average, zero_division):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
>       p, r, f, s = assert_no_warnings(
            precision_recall_fscore_support,
            y_true,
            y_pred,
            average=average,
            beta=beta,
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1782: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m________________ test_precision_recall_f1_no_labels[0-micro-1] _________________[0m

beta = 1, average = 'micro', zero_division = 0

    @pytest.mark.parametrize("beta", [1])
    @pytest.mark.parametrize("average", ["macro", "micro", "weighted", "samples"])
    @pytest.mark.parametrize("zero_division", [0, 1])
    def test_precision_recall_f1_no_labels(beta, average, zero_division):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
>       p, r, f, s = assert_no_warnings(
            precision_recall_fscore_support,
            y_true,
            y_pred,
            average=average,
            beta=beta,
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1782: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m_______________ test_precision_recall_f1_no_labels[0-weighted-1] _______________[0m

beta = 1, average = 'weighted', zero_division = 0

    @pytest.mark.parametrize("beta", [1])
    @pytest.mark.parametrize("average", ["macro", "micro", "weighted", "samples"])
    @pytest.mark.parametrize("zero_division", [0, 1])
    def test_precision_recall_f1_no_labels(beta, average, zero_division):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
>       p, r, f, s = assert_no_warnings(
            precision_recall_fscore_support,
            y_true,
            y_pred,
            average=average,
            beta=beta,
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1782: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m_______________ test_precision_recall_f1_no_labels[0-samples-1] ________________[0m

beta = 1, average = 'samples', zero_division = 0

    @pytest.mark.parametrize("beta", [1])
    @pytest.mark.parametrize("average", ["macro", "micro", "weighted", "samples"])
    @pytest.mark.parametrize("zero_division", [0, 1])
    def test_precision_recall_f1_no_labels(beta, average, zero_division):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
>       p, r, f, s = assert_no_warnings(
            precision_recall_fscore_support,
            y_true,
            y_pred,
            average=average,
            beta=beta,
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1782: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m________________ test_precision_recall_f1_no_labels[1-macro-1] _________________[0m

beta = 1, average = 'macro', zero_division = 1

    @pytest.mark.parametrize("beta", [1])
    @pytest.mark.parametrize("average", ["macro", "micro", "weighted", "samples"])
    @pytest.mark.parametrize("zero_division", [0, 1])
    def test_precision_recall_f1_no_labels(beta, average, zero_division):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
>       p, r, f, s = assert_no_warnings(
            precision_recall_fscore_support,
            y_true,
            y_pred,
            average=average,
            beta=beta,
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1782: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m________________ test_precision_recall_f1_no_labels[1-micro-1] _________________[0m

beta = 1, average = 'micro', zero_division = 1

    @pytest.mark.parametrize("beta", [1])
    @pytest.mark.parametrize("average", ["macro", "micro", "weighted", "samples"])
    @pytest.mark.parametrize("zero_division", [0, 1])
    def test_precision_recall_f1_no_labels(beta, average, zero_division):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
>       p, r, f, s = assert_no_warnings(
            precision_recall_fscore_support,
            y_true,
            y_pred,
            average=average,
            beta=beta,
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1782: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m_______________ test_precision_recall_f1_no_labels[1-weighted-1] _______________[0m

beta = 1, average = 'weighted', zero_division = 1

    @pytest.mark.parametrize("beta", [1])
    @pytest.mark.parametrize("average", ["macro", "micro", "weighted", "samples"])
    @pytest.mark.parametrize("zero_division", [0, 1])
    def test_precision_recall_f1_no_labels(beta, average, zero_division):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
>       p, r, f, s = assert_no_warnings(
            precision_recall_fscore_support,
            y_true,
            y_pred,
            average=average,
            beta=beta,
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1782: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m_______________ test_precision_recall_f1_no_labels[1-samples-1] ________________[0m

beta = 1, average = 'samples', zero_division = 1

    @pytest.mark.parametrize("beta", [1])
    @pytest.mark.parametrize("average", ["macro", "micro", "weighted", "samples"])
    @pytest.mark.parametrize("zero_division", [0, 1])
    def test_precision_recall_f1_no_labels(beta, average, zero_division):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
>       p, r, f, s = assert_no_warnings(
            precision_recall_fscore_support,
            y_true,
            y_pred,
            average=average,
            beta=beta,
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1782: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m___________ test_precision_recall_f1_no_labels_check_warnings[macro] ___________[0m

average = 'macro'

    @pytest.mark.parametrize("average", ["macro", "micro", "weighted", "samples"])
    def test_precision_recall_f1_no_labels_check_warnings(average):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
        func = precision_recall_fscore_support
        with pytest.warns(UndefinedMetricWarning):
>           p, r, f, s = func(y_true, y_pred, average=average, beta=1.0)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1815: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m___________ test_precision_recall_f1_no_labels_check_warnings[micro] ___________[0m

average = 'micro'

    @pytest.mark.parametrize("average", ["macro", "micro", "weighted", "samples"])
    def test_precision_recall_f1_no_labels_check_warnings(average):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
        func = precision_recall_fscore_support
        with pytest.warns(UndefinedMetricWarning):
>           p, r, f, s = func(y_true, y_pred, average=average, beta=1.0)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1815: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m_________ test_precision_recall_f1_no_labels_check_warnings[weighted] __________[0m

average = 'weighted'

    @pytest.mark.parametrize("average", ["macro", "micro", "weighted", "samples"])
    def test_precision_recall_f1_no_labels_check_warnings(average):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
        func = precision_recall_fscore_support
        with pytest.warns(UndefinedMetricWarning):
>           p, r, f, s = func(y_true, y_pred, average=average, beta=1.0)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1815: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m__________ test_precision_recall_f1_no_labels_check_warnings[samples] __________[0m

average = 'samples'

    @pytest.mark.parametrize("average", ["macro", "micro", "weighted", "samples"])
    def test_precision_recall_f1_no_labels_check_warnings(average):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
        func = precision_recall_fscore_support
        with pytest.warns(UndefinedMetricWarning):
>           p, r, f, s = func(y_true, y_pred, average=average, beta=1.0)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1815: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m______________ test_precision_recall_f1_no_labels_average_none[0] ______________[0m

zero_division = 0

    @pytest.mark.parametrize("zero_division", [0, 1])
    def test_precision_recall_f1_no_labels_average_none(zero_division):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
        # tp = [0, 0, 0]
        # fn = [0, 0, 0]
        # fp = [0, 0, 0]
        # support = [0, 0, 0]
        # |y_hat_i inter y_i | = [0, 0, 0]
        # |y_i| = [0, 0, 0]
        # |y_hat_i| = [0, 0, 0]
    
>       p, r, f, s = assert_no_warnings(
            precision_recall_fscore_support,
            y_true,
            y_pred,
            average=None,
            beta=1.0,
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m______________ test_precision_recall_f1_no_labels_average_none[1] ______________[0m

zero_division = 1

    @pytest.mark.parametrize("zero_division", [0, 1])
    def test_precision_recall_f1_no_labels_average_none(zero_division):
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
        # tp = [0, 0, 0]
        # fn = [0, 0, 0]
        # fp = [0, 0, 0]
        # support = [0, 0, 0]
        # |y_hat_i inter y_i | = [0, 0, 0]
        # |y_i| = [0, 0, 0]
        # |y_hat_i| = [0, 0, 0]
    
>       p, r, f, s = assert_no_warnings(
            precision_recall_fscore_support,
            y_true,
            y_pred,
            average=None,
            beta=1.0,
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m_____________ test_precision_recall_f1_no_labels_average_none_warn _____________[0m

    def test_precision_recall_f1_no_labels_average_none_warn():
        y_true = np.zeros((20, 3))
        y_pred = np.zeros_like(y_true)
    
        # tp = [0, 0, 0]
        # fn = [0, 0, 0]
        # fp = [0, 0, 0]
        # support = [0, 0, 0]
        # |y_hat_i inter y_i | = [0, 0, 0]
        # |y_i| = [0, 0, 0]
        # |y_hat_i| = [0, 0, 0]
    
        with pytest.warns(UndefinedMetricWarning):
>           p, r, f, s = precision_recall_fscore_support(
                y_true, y_pred, average=None, beta=1
            )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1875: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <20x3 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m______________________________ test_prf_warnings _______________________________[0m

    def test_prf_warnings():
        # average of per-label scores
        f, w = precision_recall_fscore_support, UndefinedMetricWarning
        for average in [None, "weighted", "macro"]:
            msg = (
                "Precision and F-score are ill-defined and "
                "being set to 0.0 in labels with no predicted samples."
                " Use `zero_division` parameter to control"
                " this behavior."
            )
            with pytest.warns(w, match=msg):
>               f([0, 1, 2], [1, 1, 2], average=average)

[1m[31msklearn/metrics/tests/test_classification.py[0m:1901: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________________ test_prf_no_warnings_if_zero_division_set[0] _________________[0m

zero_division = 0

    @pytest.mark.parametrize("zero_division", [0, 1])
    def test_prf_no_warnings_if_zero_division_set(zero_division):
        # average of per-label scores
        f = precision_recall_fscore_support
        for average in [None, "weighted", "macro"]:
>           assert_no_warnings(
                f, [0, 1, 2], [1, 1, 2], average=average, zero_division=zero_division
            )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1993: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________________ test_prf_no_warnings_if_zero_division_set[1] _________________[0m

zero_division = 1

    @pytest.mark.parametrize("zero_division", [0, 1])
    def test_prf_no_warnings_if_zero_division_set(zero_division):
        # average of per-label scores
        f = precision_recall_fscore_support
        for average in [None, "weighted", "macro"]:
>           assert_no_warnings(
                f, [0, 1, 2], [1, 1, 2], average=average, zero_division=zero_division
            )

[1m[31msklearn/metrics/tests/test_classification.py[0m:1993: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 2])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m__________________________ test_recall_warnings[warn] __________________________[0m

zero_division = 'warn'

    @pytest.mark.parametrize("zero_division", ["warn", 0, 1])
    def test_recall_warnings(zero_division):
>       assert_no_warnings(
            recall_score,
            np.array([[1, 1], [1, 1]]),
            np.array([[0, 0], [0, 0]]),
            average="micro",
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:2054: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:2146: in recall_score
    _, r, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x2 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m___________________________ test_recall_warnings[0] ____________________________[0m

zero_division = 0

    @pytest.mark.parametrize("zero_division", ["warn", 0, 1])
    def test_recall_warnings(zero_division):
>       assert_no_warnings(
            recall_score,
            np.array([[1, 1], [1, 1]]),
            np.array([[0, 0], [0, 0]]),
            average="micro",
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:2054: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:2146: in recall_score
    _, r, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x2 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m___________________________ test_recall_warnings[1] ____________________________[0m

zero_division = 1

    @pytest.mark.parametrize("zero_division", ["warn", 0, 1])
    def test_recall_warnings(zero_division):
>       assert_no_warnings(
            recall_score,
            np.array([[1, 1], [1, 1]]),
            np.array([[0, 0], [0, 0]]),
            average="micro",
            zero_division=zero_division,
        )

[1m[31msklearn/metrics/tests/test_classification.py[0m:2054: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_testing.py[0m:104: in assert_no_warnings
    result = func(*args, **kw)
[1m[31msklearn/metrics/_classification.py[0m:2146: in recall_score
    _, r, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x2 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________________________ test_precision_warnings[warn] _________________________[0m

zero_division = 'warn'

    @pytest.mark.parametrize("zero_division", ["warn", 0, 1])
    def test_precision_warnings(zero_division):
        with warnings.catch_warnings(record=True) as record:
            warnings.simplefilter("always")
>           precision_score(
                np.array([[1, 1], [1, 1]]),
                np.array([[0, 0], [0, 0]]),
                average="micro",
                zero_division=zero_division,
            )

[1m[31msklearn/metrics/tests/test_classification.py[0m:2095: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2002: in precision_score
    p, _, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x2 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m__________________________ test_precision_warnings[0] __________________________[0m

zero_division = 0

    @pytest.mark.parametrize("zero_division", ["warn", 0, 1])
    def test_precision_warnings(zero_division):
        with warnings.catch_warnings(record=True) as record:
            warnings.simplefilter("always")
>           precision_score(
                np.array([[1, 1], [1, 1]]),
                np.array([[0, 0], [0, 0]]),
                average="micro",
                zero_division=zero_division,
            )

[1m[31msklearn/metrics/tests/test_classification.py[0m:2095: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2002: in precision_score
    p, _, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x2 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m__________________________ test_precision_warnings[1] __________________________[0m

zero_division = 1

    @pytest.mark.parametrize("zero_division", ["warn", 0, 1])
    def test_precision_warnings(zero_division):
        with warnings.catch_warnings(record=True) as record:
            warnings.simplefilter("always")
>           precision_score(
                np.array([[1, 1], [1, 1]]),
                np.array([[0, 0], [0, 0]]),
                average="micro",
                zero_division=zero_division,
            )

[1m[31msklearn/metrics/tests/test_classification.py[0m:2095: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2002: in precision_score
    p, _, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x2 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m__________________________ test_fscore_warnings[warn] __________________________[0m

zero_division = 'warn'

    @pytest.mark.parametrize("zero_division", ["warn", 0, 1])
    def test_fscore_warnings(zero_division):
        with warnings.catch_warnings(record=True) as record:
            warnings.simplefilter("always")
    
            for score in [f1_score, partial(fbeta_score, beta=2)]:
>               score(
                    np.array([[1, 1], [1, 1]]),
                    np.array([[0, 0], [0, 0]]),
                    average="micro",
                    zero_division=zero_division,
                )

[1m[31msklearn/metrics/tests/test_classification.py[0m:2137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:1194: in f1_score
    return fbeta_score(
[1m[31msklearn/metrics/_classification.py[0m:1335: in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x2 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m___________________________ test_fscore_warnings[0] ____________________________[0m

zero_division = 0

    @pytest.mark.parametrize("zero_division", ["warn", 0, 1])
    def test_fscore_warnings(zero_division):
        with warnings.catch_warnings(record=True) as record:
            warnings.simplefilter("always")
    
            for score in [f1_score, partial(fbeta_score, beta=2)]:
>               score(
                    np.array([[1, 1], [1, 1]]),
                    np.array([[0, 0], [0, 0]]),
                    average="micro",
                    zero_division=zero_division,
                )

[1m[31msklearn/metrics/tests/test_classification.py[0m:2137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:1194: in f1_score
    return fbeta_score(
[1m[31msklearn/metrics/_classification.py[0m:1335: in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x2 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m___________________________ test_fscore_warnings[1] ____________________________[0m

zero_division = 1

    @pytest.mark.parametrize("zero_division", ["warn", 0, 1])
    def test_fscore_warnings(zero_division):
        with warnings.catch_warnings(record=True) as record:
            warnings.simplefilter("always")
    
            for score in [f1_score, partial(fbeta_score, beta=2)]:
>               score(
                    np.array([[1, 1], [1, 1]]),
                    np.array([[0, 0], [0, 0]]),
                    average="micro",
                    zero_division=zero_division,
                )

[1m[31msklearn/metrics/tests/test_classification.py[0m:2137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:1194: in f1_score
    return fbeta_score(
[1m[31msklearn/metrics/_classification.py[0m:1335: in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <2x2 sparse matrix of type '<class 'numpy.int64'>'
	with 4 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m___________________ test_prf_average_binary_data_non_binary ____________________[0m

    def test_prf_average_binary_data_non_binary():
        # Error if user does not explicitly set non-binary average mode
        y_true_mc = [1, 2, 3, 3]
        y_pred_mc = [1, 2, 3, 1]
        msg_mc = (
            r"Target is multiclass but average='binary'. Please "
            r"choose another average setting, one of \["
            r"None, 'micro', 'macro', 'weighted'\]."
        )
        y_true_ind = np.array([[0, 1, 1], [1, 0, 0], [0, 0, 1]])
        y_pred_ind = np.array([[0, 1, 0], [1, 0, 0], [0, 0, 1]])
        msg_ind = (
            r"Target is multilabel-indicator but average='binary'. Please "
            r"choose another average setting, one of \["
            r"None, 'micro', 'macro', 'weighted', 'samples'\]."
        )
    
        for y_true, y_pred, msg in [
            (y_true_mc, y_pred_mc, msg_mc),
            (y_true_ind, y_pred_ind, msg_ind),
        ]:
            for metric in [
                precision_score,
                recall_score,
                f1_score,
                partial(fbeta_score, beta=2),
            ]:
                with pytest.raises(ValueError, match=msg):
>                   metric(y_true, y_pred)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2002: in precision_score
    p, _, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([1, 2, 3, 3])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m____________________________ test_hinge_loss_binary ____________________________[0m

    def test_hinge_loss_binary():
        y_true = np.array([-1, 1, 1, -1])
        pred_decision = np.array([-8.5, 0.5, 1.5, -0.3])
>       assert hinge_loss(y_true, pred_decision) == 1.2 / 4

[1m[31msklearn/metrics/tests/test_classification.py[0m:2310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2880: in hinge_loss
    y_true = lbin.fit_transform(y_true)[:, 0]
[1m[31msklearn/utils/_set_output.py[0m:142: in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
[1m[31msklearn/preprocessing/_label.py[0m:334: in fit_transform
    return self.fit(y).transform(y)
[1m[31msklearn/preprocessing/_label.py[0m:311: in fit
    self.classes_ = unique_labels(y)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([-1,  1,  1, -1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_______________________ test_log_loss_eps_auto[float64] ________________________[0m

global_dtype = <class 'numpy.float64'>

    def test_log_loss_eps_auto(global_dtype):
        """Check the behaviour of `eps="auto"` that changes depending on the input
        array dtype.
        Non-regression test for:
        https://github.com/scikit-learn/scikit-learn/issues/24315
        """
        y_true = np.array([0, 1], dtype=global_dtype)
        y_pred = y_true.copy()
    
>       loss = log_loss(y_true, y_pred, eps="auto")

[1m[31msklearn/metrics/tests/test_classification.py[0m:2574: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:2683: in log_loss
    lb.fit(y_true)
[1m[31msklearn/preprocessing/_label.py[0m:311: in fit
    self.classes_ = unique_labels(y)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0., 1.])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m________________________ test_log_loss_eps_auto_float16 ________________________[0m

    def test_log_loss_eps_auto_float16():
        """Check the behaviour of `eps="auto"` for np.float16"""
        y_true = np.array([0, 1], dtype=np.float16)
        y_pred = y_true.copy()
    
>       loss = log_loss(y_true, y_pred, eps="auto")

[1m[31msklearn/metrics/tests/test_classification.py[0m:2583: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:2683: in log_loss
    lb.fit(y_true)
[1m[31msklearn/preprocessing/_label.py[0m:311: in fit
    self.classes_ = unique_labels(y)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0., 1.], dtype=float16)

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m_____________________ test_balanced_accuracy_score_unseen ______________________[0m

    def test_balanced_accuracy_score_unseen():
        msg = "y_pred contains classes not in y_true"
        with pytest.warns(UserWarning, match=msg):
>           balanced_accuracy_score([0, 0, 0], [0, 0, 1])

[1m[31msklearn/metrics/tests/test_classification.py[0m:2644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:2236: in balanced_accuracy_score
    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:332: in confusion_matrix
    labels = unique_labels(y_true, y_pred)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m______ test_classification_metric_pos_label_types[classes0-jaccard_score] ______[0m

metric = <function jaccard_score at 0x74c48dc52d30>, classes = (False, True)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:832: in jaccard_score
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([False,  True, False, False, False,  True, False, False, False,
        True])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
            return y.to_numpy(dtype="float64")
        elif pd.api.types.is_bool_dtype(y):
>           return y.to_numpy(dtype="bool")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:79: AttributeError
[31m[1m________ test_classification_metric_pos_label_types[classes0-f1_score] _________[0m

metric = <function f1_score at 0x74c48dc53550>, classes = (False, True)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:1194: in f1_score
    return fbeta_score(
[1m[31msklearn/metrics/_classification.py[0m:1335: in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([False,  True, False, False, False,  True, False, False, False,
        True])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
            return y.to_numpy(dtype="float64")
        elif pd.api.types.is_bool_dtype(y):
>           return y.to_numpy(dtype="bool")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:79: AttributeError
[31m[1m_________ test_classification_metric_pos_label_types[classes0-metric2] _________[0m

metric = functools.partial(<function fbeta_score at 0x74c48dc53310>, beta=0.5)
classes = (False, True)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1335: in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([False,  True, False, False, False,  True, False, False, False,
        True])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
            return y.to_numpy(dtype="float64")
        elif pd.api.types.is_bool_dtype(y):
>           return y.to_numpy(dtype="bool")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:79: AttributeError
[31m[1m_ test_classification_metric_pos_label_types[classes0-precision_recall_fscore_support] _[0m

metric = <function precision_recall_fscore_support at 0x74c48dc53790>
classes = (False, True)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([False,  True, False, False, False,  True, False, False, False,
        True])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
            return y.to_numpy(dtype="float64")
        elif pd.api.types.is_bool_dtype(y):
>           return y.to_numpy(dtype="bool")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:79: AttributeError
[31m[1m_____ test_classification_metric_pos_label_types[classes0-precision_score] _____[0m

metric = <function precision_score at 0x74c48dc538b0>, classes = (False, True)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2002: in precision_score
    p, _, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([False,  True, False, False, False,  True, False, False, False,
        True])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
            return y.to_numpy(dtype="float64")
        elif pd.api.types.is_bool_dtype(y):
>           return y.to_numpy(dtype="bool")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:79: AttributeError
[31m[1m______ test_classification_metric_pos_label_types[classes0-recall_score] _______[0m

metric = <function recall_score at 0x74c48dc53940>, classes = (False, True)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2146: in recall_score
    _, r, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([False,  True, False, False, False,  True, False, False, False,
        True])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
            return y.to_numpy(dtype="float64")
        elif pd.api.types.is_bool_dtype(y):
>           return y.to_numpy(dtype="bool")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:79: AttributeError
[31m[1m______ test_classification_metric_pos_label_types[classes1-jaccard_score] ______[0m

metric = <function jaccard_score at 0x74c48dc52d30>, classes = (0, 1)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:832: in jaccard_score
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________ test_classification_metric_pos_label_types[classes1-f1_score] _________[0m

metric = <function f1_score at 0x74c48dc53550>, classes = (0, 1)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:1194: in f1_score
    return fbeta_score(
[1m[31msklearn/metrics/_classification.py[0m:1335: in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________ test_classification_metric_pos_label_types[classes1-metric2] _________[0m

metric = functools.partial(<function fbeta_score at 0x74c48dc53310>, beta=0.5)
classes = (0, 1)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1335: in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_ test_classification_metric_pos_label_types[classes1-precision_recall_fscore_support] _[0m

metric = <function precision_recall_fscore_support at 0x74c48dc53790>
classes = (0, 1)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_____ test_classification_metric_pos_label_types[classes1-precision_score] _____[0m

metric = <function precision_score at 0x74c48dc538b0>, classes = (0, 1)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2002: in precision_score
    p, _, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m______ test_classification_metric_pos_label_types[classes1-recall_score] _______[0m

metric = <function recall_score at 0x74c48dc53940>, classes = (0, 1)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2146: in recall_score
    _, r, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m______ test_classification_metric_pos_label_types[classes2-jaccard_score] ______[0m

metric = <function jaccard_score at 0x74c48dc52d30>, classes = (0.0, 1.0)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:832: in jaccard_score
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0., 1., 0., 0., 0., 1., 0., 0., 0., 1.])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m________ test_classification_metric_pos_label_types[classes2-f1_score] _________[0m

metric = <function f1_score at 0x74c48dc53550>, classes = (0.0, 1.0)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_param_validation.py[0m:192: in wrapper
    return func(*args, **kwargs)
[1m[31msklearn/metrics/_classification.py[0m:1194: in f1_score
    return fbeta_score(
[1m[31msklearn/metrics/_classification.py[0m:1335: in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0., 1., 0., 0., 0., 1., 0., 0., 0., 1.])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m_________ test_classification_metric_pos_label_types[classes2-metric2] _________[0m

metric = functools.partial(<function fbeta_score at 0x74c48dc53310>, beta=0.5)
classes = (0.0, 1.0)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1335: in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0., 1., 0., 0., 0., 1., 0., 0., 0., 1.])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m_ test_classification_metric_pos_label_types[classes2-precision_recall_fscore_support] _[0m

metric = <function precision_recall_fscore_support at 0x74c48dc53790>
classes = (0.0, 1.0)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0., 1., 0., 0., 0., 1., 0., 0., 0., 1.])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m_____ test_classification_metric_pos_label_types[classes2-precision_score] _____[0m

metric = <function precision_score at 0x74c48dc538b0>, classes = (0.0, 1.0)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2002: in precision_score
    p, _, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0., 1., 0., 0., 0., 1., 0., 0., 0., 1.])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m______ test_classification_metric_pos_label_types[classes2-recall_score] _______[0m

metric = <function recall_score at 0x74c48dc53940>, classes = (0.0, 1.0)

    @pytest.mark.parametrize(
        "metric",
        [
            jaccard_score,
            f1_score,
            partial(fbeta_score, beta=0.5),
            precision_recall_fscore_support,
            precision_score,
            recall_score,
            brier_score_loss,
        ],
    )
    @pytest.mark.parametrize(
        "classes", [(False, True), (0, 1), (0.0, 1.0), ("zero", "one")]
    )
    def test_classification_metric_pos_label_types(metric, classes):
        """Check that the metric works with different types of `pos_label`.
    
        We can expect `pos_label` to be a bool, an integer, a float, a string.
        No error should be raised for those types.
        """
        rng = np.random.RandomState(42)
        n_samples, pos_label = 10, classes[-1]
        y_true = rng.choice(classes, size=n_samples, replace=True)
        if metric is brier_score_loss:
            # brier score loss requires probabilities
            y_pred = rng.uniform(size=n_samples)
        else:
            y_pred = y_true.copy()
>       result = metric(y_true, y_pred, pos_label=pos_label)

[1m[31msklearn/metrics/tests/test_classification.py[0m:2697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/metrics/_classification.py[0m:2146: in recall_score
    _, r, _, _ = precision_recall_fscore_support(
[1m[31msklearn/metrics/_classification.py[0m:1621: in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
[1m[31msklearn/metrics/_classification.py[0m:1425: in _check_set_wise_labels
    present_labels = unique_labels(y_true, y_pred).tolist()
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0., 1., 0., 0., 0., 1., 0., 0., 0., 1.])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
            return y.to_numpy(dtype="int64")
        elif pd.api.types.is_float_dtype(y):
>           return y.to_numpy(dtype="float64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:77: AttributeError
[31m[1m___________________ test_label_binarizer_set_label_encoding ____________________[0m

    def test_label_binarizer_set_label_encoding():
        lb = LabelBinarizer(neg_label=-2, pos_label=0)
    
        # two-class case with pos_label=0
        inp = np.array([0, 1, 1, 0])
        expected = np.array([[-2, 0, 0, -2]]).T
>       got = lb.fit_transform(inp)

[1m[31msklearn/preprocessing/tests/test_label.py[0m:98: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/_set_output.py[0m:142: in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
[1m[31msklearn/preprocessing/_label.py[0m:334: in fit_transform
    return self.fit(y).transform(y)
[1m[31msklearn/preprocessing/_label.py[0m:311: in fit
    self.classes_ = unique_labels(y)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 1, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_________________________ test_label_binarizer_errors __________________________[0m

    @ignore_warnings
    def test_label_binarizer_errors():
        # Check that invalid arguments yield ValueError
        one_class = np.array([0, 0, 0, 0])
>       lb = LabelBinarizer().fit(one_class)

[1m[31msklearn/preprocessing/tests/test_label.py[0m:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/preprocessing/_label.py[0m:311: in fit
    self.classes_ = unique_labels(y)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 0, 0, 0])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________________________ test_label_binarize_multilabel ________________________[0m

    def test_label_binarize_multilabel():
        y_ind = np.array([[0, 1, 0], [1, 1, 1], [0, 0, 0]])
        classes = [0, 1, 2]
        pos_label = 2
        neg_label = 0
        expected = pos_label * y_ind
        y_sparse = [
            sparse_matrix(y_ind)
            for sparse_matrix in [
                coo_matrix,
                csc_matrix,
                csr_matrix,
                dok_matrix,
                lil_matrix,
            ]
        ]
    
        for y in [y_ind] + y_sparse:
>           check_binarized_results(y, classes, pos_label, neg_label, expected)

[1m[31msklearn/preprocessing/tests/test_label.py[0m:640: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/preprocessing/tests/test_label.py[0m:580: in check_binarized_results
    binarized = lb.fit_transform(y)
[1m[31msklearn/utils/_set_output.py[0m:142: in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
[1m[31msklearn/preprocessing/_label.py[0m:334: in fit_transform
    return self.fit(y).transform(y)
[1m[31msklearn/preprocessing/_label.py[0m:311: in fit
    self.classes_ = unique_labels(y)
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([[0, 1, 0],
       [1, 1, 1],
       [0, 0, 0]])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m______________________________ test_unique_labels ______________________________[0m

    def test_unique_labels():
        # Empty iterable
        with pytest.raises(ValueError):
            unique_labels()
    
        # Multiclass problem
        assert_array_equal(unique_labels(range(10)), np.arange(10))
>       assert_array_equal(unique_labels(np.arange(10)), np.arange(10))

[1m[31msklearn/utils/tests/test_multiclass.py[0m:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_______________________ test_unique_labels_non_specific ________________________[0m

    def test_unique_labels_non_specific():
        # Test unique_labels with a variety of collected examples
    
        # Smoke test for all supported format
        for format in ["binary", "multiclass", "multilabel-indicator"]:
            for y in EXAMPLES[format]:
>               unique_labels(y)

[1m[31msklearn/utils/tests/test_multiclass.py[0m:213: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = array([0, 1, 1, 1, 0, 0, 0, 1, 1, 1])

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m________________________ test_unique_labels_mixed_types ________________________[0m

    def test_unique_labels_mixed_types():
        # Mix with binary or multiclass and multilabel
        mix_clf_format = product(
            EXAMPLES["multilabel-indicator"], EXAMPLES["multiclass"] + EXAMPLES["binary"]
        )
    
        for y_multilabel, y_multiclass in mix_clf_format:
            with pytest.raises(ValueError):
>               unique_labels(y_multiclass, y_multilabel)

[1m[31msklearn/utils/tests/test_multiclass.py[0m:239: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31msklearn/utils/multiclass.py[0m:86: in unique_labels
    ys = [convert_nullable_dtype(y) for y in ys]
[1m[31msklearn/utils/multiclass.py[0m:86: in <listcomp>
    ys = [convert_nullable_dtype(y) for y in ys]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

y = <10x10 sparse matrix of type '<class 'numpy.int64'>'
	with 56 stored elements in Compressed Sparse Row format>

    def convert_nullable_dtype(y):
        if pd.api.types.is_integer_dtype(y):
>           return y.to_numpy(dtype="int64")
[1m[31mE           AttributeError: 'csr_matrix' object has no attribute 'to_numpy'[0m

[1m[31msklearn/utils/multiclass.py[0m:75: AttributeError
[31m[1m_____________________ test_type_of_target_pandas_nullable ______________________[0m

    def test_type_of_target_pandas_nullable():
        """Check that type_of_target works with pandas nullable dtypes."""
        pd = pytest.importorskip("pandas")
    
        for dtype in ["Int32", "Float32"]:
            y_true = pd.Series([1, 0, 2, 3, 4], dtype=dtype)
            assert type_of_target(y_true) == "multiclass"
    
            y_true = pd.Series([1, 0, 1, 0], dtype=dtype)
            assert type_of_target(y_true) == "binary"
    
        y_true = pd.DataFrame([[1.4, 3.1], [3.1, 1.4]], dtype="Float32")
>       assert type_of_target(y_true) == "continuous-multioutput"
[1m[31mE       AssertionError: assert 'unknown' == 'continuous-multioutput'[0m
[1m[31mE         - continuous-multioutput[0m
[1m[31mE         + unknown[0m

[1m[31msklearn/utils/tests/test_multiclass.py[0m:361: AssertionError
==================================== PASSES ====================================
[36m[1m=========================== short test summary info ============================[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_zero_division_warning[warn][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_zero_division_warning[0][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_zero_division_warning[1][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_multilabel_accuracy_score_subset_accuracy[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_average_precision_score_score_non_binary_class[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_average_precision_score_duplicate_values[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_average_precision_score_tied_values[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_likelihood_ratios_errors[params0-class_likelihood_ratios only supports binary classification problems, got targets of type: multiclass][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_multiclass_subset_labels[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_error[empty list][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_error[unknown labels][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_on_zero_length_input[binary][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_on_zero_length_input[multiclass][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_multiclass_with_string_label[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_multiclass_with_unicode_label[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_multiclass_with_long_string_label[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_multilabel_zero_one_loss_subset[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_multilabel_hamming_loss[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest__check_targets[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest__check_targets_multiclass_with_both_y_true_and_y_pred_binary[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_hinge_loss_multiclass[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_hinge_loss_multiclass_missing_labels_with_labels_none[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_hinge_loss_multiclass_no_consistent_pred_decision_shape[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_hinge_loss_multiclass_with_missing_labels[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_hinge_loss_multiclass_missing_labels_only_two_unq_in_y_true[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_hinge_loss_multiclass_invariance_lists[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_log_loss[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_log_loss_pandas_input[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_brier_score_loss[0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_balanced_accuracy_score[y_true0-y_pred0][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_balanced_accuracy_score[y_true1-y_pred1][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_balanced_accuracy_score[y_true2-y_pred2][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes0-brier_score_loss][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes1-brier_score_loss][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes2-brier_score_loss][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes3-jaccard_score][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes3-f1_score][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes3-metric2][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes3-precision_recall_fscore_support][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes3-precision_score][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes3-recall_score][0m
[32mPASSED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes3-brier_score_loss][0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_binarizer[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_binarizer_unseen_labels[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_binarizer_pandas_nullable[Int64][0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_binarizer_pandas_nullable[Float64][0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_binarizer_pandas_nullable[boolean][0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_encoder[int64][0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_encoder[object][0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_encoder[str][0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_encoder_negative_ints[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_encoder_str_bad_shape[str][0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_encoder_str_bad_shape[object][0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_encoder_errors[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_encoder_empty_array[int64][0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_encoder_empty_array[object][0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_encoder_empty_array[str][0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_sparse_output_multilabel_binarizer[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_multilabel_binarizer[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_multilabel_binarizer_empty_sample[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_multilabel_binarizer_unknown_class[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_multilabel_binarizer_given_classes[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_multilabel_binarizer_multiple_calls[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_multilabel_binarizer_same_length_sequence[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_multilabel_binarizer_non_integer_labels[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_multilabel_binarizer_non_unique[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_multilabel_binarizer_inverse_validation[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_binarize_with_class_order[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_binarize_binary[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_binarize_multiclass[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_invalid_input_label_binarize[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_inverse_binarize_multiclass[0m
[32mPASSED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_nan_label_encoder[0m
[32mPASSED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_is_multilabel[0m
[32mPASSED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_check_classification_targets[0m
[32mPASSED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_type_of_target[0m
[32mPASSED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_type_of_target_pandas_sparse[0m
[32mPASSED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_unique_labels_pandas_nullable[Int64][0m
[32mPASSED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_unique_labels_pandas_nullable[Float64][0m
[32mPASSED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_unique_labels_pandas_nullable[boolean][0m
[32mPASSED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_class_distribution[0m
[32mPASSED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_safe_split_with_precomputed_kernel[0m
[32mPASSED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_ovr_decision_function[0m
[33mSKIPPED[0m [1] sklearn/metrics/tests/test_classification.py:2565: Set SKLEARN_RUN_FLOAT32_TESTS=1 to run float32 dtype tests
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_dictionary_output[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_output_dict_empty_input[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_score_binary[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f_binary_single_class[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f_extra_labels[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f_ignored_labels[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_fscore_support_errors[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f_unused_pos_label[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_binary[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_multilabel_confusion_matrix_binary[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_multilabel_confusion_matrix_multiclass[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_multilabel_confusion_matrix_multilabel[0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_multilabel_confusion_matrix_errors[0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_normalize[true-f-0.333333333][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_normalize[pred-f-0.333333333][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_normalize[all-f-0.1111111111][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_normalize[None-i-2][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_normalize_single_class[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_likelihood_ratios_warnings[params0-samples of only one class were seen during testing][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_likelihood_ratios_warnings[params1-positive_likelihood_ratio ill-defined and being set to nan][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_likelihood_ratios_warnings[params2-no samples predicted for the positive class][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_likelihood_ratios_warnings[params3-negative_likelihood_ratio ill-defined and being set to nan][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_likelihood_ratios_warnings[params4-no samples of the positive class were present in the testing set][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_likelihood_ratios[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_cohen_kappa[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_matthews_corrcoef_nan[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_matthews_corrcoef_against_numpy_corrcoef[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_matthews_corrcoef_against_jurman[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_matthews_corrcoef[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_matthews_corrcoef_multiclass[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_matthews_corrcoef_overflow[100][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_matthews_corrcoef_overflow[10000][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_score_multiclass[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_refcall_f1_score_multilabel_unordered_labels[samples][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_refcall_f1_score_multilabel_unordered_labels[micro][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_refcall_f1_score_multilabel_unordered_labels[macro][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_refcall_f1_score_multilabel_unordered_labels[weighted][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_refcall_f1_score_multilabel_unordered_labels[None][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_score_binary_averaged[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_zero_precision_recall[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_on_zero_length_input[None][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_dtype[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_pandas_nullable[Int64][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_pandas_nullable[Float64][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_confusion_matrix_pandas_nullable[boolean][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_multiclass[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_multiclass_balanced[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_multiclass_with_label_detection[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_multiclass_with_digits[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_labels_target_names_unequal_length[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_report_no_labels_target_names_unequal_length[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_multilabel_classification_report[0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_jaccard_score_validation[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_multilabel_jaccard_score[0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_multiclass_jaccard_score[0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_average_binary_jaccard_score[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_jaccard_score_zero_division_warning[0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_jaccard_score_zero_division_set_value[0-0][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_jaccard_score_zero_division_set_value[1-0.5][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_score_multilabel_1[0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_score_multilabel_2[0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_score_with_an_empty_prediction[warn][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_score_with_an_empty_prediction[0][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_score_with_an_empty_prediction[1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels[0-macro-1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels[0-micro-1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels[0-weighted-1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels[0-samples-1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels[1-macro-1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels[1-micro-1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels[1-weighted-1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels[1-samples-1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels_check_warnings[macro][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels_check_warnings[micro][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels_check_warnings[weighted][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels_check_warnings[samples][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels_average_none[0][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels_average_none[1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_recall_f1_no_labels_average_none_warn[0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_prf_warnings[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_prf_no_warnings_if_zero_division_set[0][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_prf_no_warnings_if_zero_division_set[1][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_recall_warnings[warn][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_recall_warnings[0][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_recall_warnings[1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_warnings[warn][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_warnings[0][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_precision_warnings[1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_fscore_warnings[warn][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_fscore_warnings[0][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_fscore_warnings[1][0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_prf_average_binary_data_non_binary[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_hinge_loss_binary[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_log_loss_eps_auto[float64][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_log_loss_eps_auto_float16[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_balanced_accuracy_score_unseen[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes0-jaccard_score][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes0-f1_score][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes0-metric2][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes0-precision_recall_fscore_support][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes0-precision_score][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes0-recall_score][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes1-jaccard_score][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes1-f1_score][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes1-metric2][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes1-precision_recall_fscore_support][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes1-precision_score][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes1-recall_score][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes2-jaccard_score][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes2-f1_score][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes2-metric2][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes2-precision_recall_fscore_support][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes2-precision_score][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/metrics/tests/test_classification.py::[1mtest_classification_metric_pos_label_types[classes2-recall_score][0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_binarizer_set_label_encoding[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_binarizer_errors[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/preprocessing/tests/test_label.py::[1mtest_label_binarize_multilabel[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_unique_labels[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_unique_labels_non_specific[0m - AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_unique_labels_mixed_types[0m - AttributeError: 'csr_matrix' object has no attribute 'to_numpy'
[31mFAILED[0m sklearn/utils/tests/test_multiclass.py::[1mtest_type_of_target_pandas_nullable[0m - AssertionError: assert 'unknown' == 'continuous-multioutput'
[31m=========== [31m[1m121 failed[0m, [32m83 passed[0m, [33m1 skipped[0m, [33m13 warnings[0m[31m in 13.57s[0m[31m ============[0m
+ git checkout 6adb209acd63825affc884abcd85381f148fb1b0 sklearn/metrics/tests/test_classification.py sklearn/preprocessing/tests/test_label.py sklearn/utils/tests/test_multiclass.py
Updated 3 paths from ce7e16a53

