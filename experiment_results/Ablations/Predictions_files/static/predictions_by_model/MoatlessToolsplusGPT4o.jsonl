{"instance_id": "astropy__astropy-14365", "model_patch": "diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -68,7 +68,7 @@ def _line_type(line, delimiter=None):\n     _new_re = rf\"NO({sep}NO)+\"\n     _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*)\"\n     _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\\s*(\\!(?P<comment>.*))?\\s*$\"\n-    _line_type_re = re.compile(_type_re)\n+    _line_type_re = re.compile(_type_re, re.IGNORECASE)\n     line = line.strip()\n     if not line:\n         return \"comment\"", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "astropy__astropy-6938", "model_patch": "diff --git a/astropy/io/fits/fitsrec.py b/astropy/io/fits/fitsrec.py\n--- a/astropy/io/fits/fitsrec.py\n+++ b/astropy/io/fits/fitsrec.py\n@@ -1261,7 +1261,7 @@ class FITS_rec(np.recarray):\n \n         # Replace exponent separator in floating point numbers\n         if 'D' in format:\n-            output_field.replace(encode_ascii('E'), encode_ascii('D'))\n+            output_field = output_field.replace(encode_ascii('E'), encode_ascii('D'))\n \n \n def _get_recarray_field(array, key):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "astropy__astropy-7746", "model_patch": "diff --git a/astropy/wcs/wcs.py b/astropy/wcs/wcs.py\n--- a/astropy/wcs/wcs.py\n+++ b/astropy/wcs/wcs.py\n@@ -1212,6 +1212,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n         \"\"\"\n \n         def _return_list_of_arrays(axes, origin):\n+            if all(len(x) == 0 for x in axes):\n+                return [np.array([]) for _ in range(self.naxis)]\n             try:\n                 axes = np.broadcast_arrays(*axes)\n             except ValueError:\n@@ -1231,6 +1233,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n                     for i in range(output.shape[1])]\n \n         def _return_single_array(xy, origin):\n+            if xy.size == 0:\n+                return np.array([])\n             if xy.shape[-1] != self.naxis:\n                 raise ValueError(\n                     \"When providing two arguments, the array must be \"\n@@ -1241,7 +1245,6 @@ reduce these to 2 dimensions using the naxis kwarg.\n             if ra_dec_order and sky == 'output':\n                 result = self._normalize_sky(result)\n             return result\n-\n         if len(args) == 2:\n             try:\n                 xy, origin = args\n@@ -1349,6 +1352,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n     def wcs_pix2world(self, *args, **kwargs):\n         if self.wcs is None:\n             raise ValueError(\"No basic WCS settings were created.\")\n+        if all(isinstance(arg, (list, np.ndarray)) and len(arg) == 0 for arg in args[:-1]):\n+            return [np.array([]) for _ in range(self.naxis)]\n         return self._array_converter(\n             lambda xy, o: self.wcs.p2s(xy, o)['world'],\n             'output', *args, **kwargs)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-11742", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -975,8 +975,17 @@ class CharField(Field):\n                     id='fields.E121',\n                 )\n             ]\n-        else:\n-            return []\n+        elif self.choices:\n+            longest_choice = max((len(str(choice[0])) for choice in self.choices), default=0)\n+            if self.max_length < longest_choice:\n+                return [\n+                    checks.Error(\n+                        \"'max_length' must be at least as long as the longest choice (%d characters).\" % longest_choice,\n+                        obj=self,\n+                        id='fields.E122',\n+                    )\n+                ]\n+        return []\n \n     def cast_db_type(self, connection):\n         if self.max_length is None:", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-11910", "model_patch": "diff --git a/django/db/migrations/operations/fields.py b/django/db/migrations/operations/fields.py\n--- a/django/db/migrations/operations/fields.py\n+++ b/django/db/migrations/operations/fields.py\n@@ -228,8 +228,15 @@ class AlterField(FieldOperation):\n             for n, f in\n             state.models[app_label, self.model_name_lower].fields\n         ]\n-        # TODO: investigate if old relational fields must be reloaded or if it's\n-        # sufficient if the new field is (#27737).\n+        # Update to_fields in related models to refer to the new field name\n+        for (model_app_label, model_name), model_state in state.models.items():\n+            for index, (name, f) in enumerate(model_state.fields):\n+                if f.remote_field and f.remote_field.model == state.models[app_label, self.model_name_lower].name:\n+                    if f.to_fields:\n+                        f.to_fields = tuple([\n+                            self.name if to_field_name == self.name else to_field_name\n+                            for to_field_name in f.to_fields\n+                        ])\n         # Delay rendering of relationships if it's not a relational field and\n         # not referenced by a foreign key.\n         delay = (\n@@ -237,7 +244,6 @@ class AlterField(FieldOperation):\n             not is_referenced_by_foreign_key(state, self.model_name_lower, self.field, self.name)\n         )\n         state.reload_model(app_label, self.model_name_lower, delay=delay)\n-\n     def database_forwards(self, app_label, schema_editor, from_state, to_state):\n         to_model = to_state.apps.get_model(app_label, self.model_name)\n         if self.allow_migrate_model(schema_editor.connection.alias, to_model):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-12308", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -398,6 +398,8 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+    elif isinstance(field, models.JSONField):\n+        return field.formfield().prepare_value(value)\n     else:\n         return display_for_value(value, empty_value_display)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-12747", "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -442,4 +442,11 @@ class Collector:\n         for model, instances in self.data.items():\n             for instance in instances:\n                 setattr(instance, model._meta.pk.attname, None)\n+\n+        # Ensure all models are represented in the deleted_counter with zero count if not present\n+        all_models = set(self.data.keys()).union(set(self.field_updates.keys()))\n+        for model in all_models:\n+            if model._meta.label not in deleted_counter:\n+                deleted_counter[model._meta.label] = 0\n+\n         return sum(deleted_counter.values()), dict(deleted_counter)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-14534", "model_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -277,7 +277,7 @@ class BoundWidget:\n \n     @property\n     def id_for_label(self):\n-        return 'id_%s_%s' % (self.data['name'], self.data['index'])\n+        return self.data['attrs']['id']\n \n     @property\n     def choice_label(self):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-14997", "model_patch": "diff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -278,6 +278,11 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         body_copy['__module__'] = model.__module__\n         new_model = type('New%s' % model._meta.object_name, model.__bases__, body_copy)\n \n+        # Remove unique constraints before remaking the table\n+        for constraint in constraints:\n+            if isinstance(constraint, UniqueConstraint):\n+                self.execute(self._delete_constraint_sql(model, constraint))\n+\n         # Create a new table with the updated schema.\n         self.create_model(new_model)\n \n@@ -298,10 +303,16 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n             disable_constraints=False,\n         )\n \n+        # Re-add unique constraints after remaking the table\n+        for constraint in constraints:\n+            if isinstance(constraint, UniqueConstraint):\n+                self.execute(self._create_constraint_sql(model, constraint))\n+\n         # Run deferred SQL on correct table\n-        for sql in self.deferred_sql:\n-            self.execute(sql)\n+        deferred_sql = self.deferred_sql\n         self.deferred_sql = []\n+        for sql in deferred_sql:\n+            self.execute(sql)\n         # Fix any PK-removed field\n         if restore_pk_field:\n             restore_pk_field.primary_key = True", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-16910", "model_patch": "diff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -437,6 +437,11 @@ class ReverseOneToOneDescriptor:\n         query = {\"%s__in\" % self.related.field.name: instances}\n         queryset = queryset.filter(**query)\n \n+        if queryset._fields is not None:\n+            select_mask = queryset.query.get_select_mask()\n+            related_select_mask = select_mask.get(self.related.field, {})\n+            queryset.query.add_immediate_loading(related_select_mask)\n+\n         # Since we're going to assign directly in the cache,\n         # we must manage the reverse relation cache manually.\n         for rel_obj in queryset:\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1744,6 +1744,22 @@ class QuerySet(AltersData):\n                 raise ValueError(\"only() is not supported with FilteredRelation.\")\n         clone = self._chain()\n         clone.query.add_immediate_loading(fields)\n+        if clone.query.select_related:\n+            select_related = clone.query.select_related\n+            if isinstance(select_related, dict):\n+                for field in fields:\n+                    parts = field.split(LOOKUP_SEP)\n+                    current = select_related\n+                    for part in parts[:-1]:\n+                        if part in current:\n+                            current = current[part]\n+                        else:\n+                            break\n+                    else:\n+                        if parts[-1] in current:\n+                            current[parts[-1]] = {}\n+            elif isinstance(select_related, bool):\n+                clone.query.select_related = {field.split(LOOKUP_SEP)[0]: {} for field in fields}\n         return clone\n \n     def using(self, alias):\ndiff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -1285,8 +1285,9 @@ class SQLCompiler:\n                     from_parent=opts.model,\n                 )\n                 for col in columns:\n-                    select_fields.append(len(select))\n-                    select.append((col, None))\n+                    if col[0] in related_select_mask:\n+                        select_fields.append(len(select))\n+                        select.append((col, None))\n                 klass_info[\"select_fields\"] = select_fields\n                 next = requested.get(related_field.related_query_name(), {})\n                 next_klass_infos = self.get_related_selections(", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "matplotlib__matplotlib-25311", "model_patch": "diff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -93,6 +93,15 @@ class DraggableLegend(DraggableOffsetBox):\n         loc_in_bbox = self.legend.axes.transAxes.transform(loc_in_canvas)\n         self.legend.set_bbox_to_anchor(loc_in_bbox)\n \n+    def __getstate__(self):\n+        state = self.__dict__.copy()\n+        state.pop('legend', None)\n+        return state\n+\n+    def __setstate__(self, state):\n+        self.__dict__.update(state)\n+        self.legend = state.get('legend', None)\n+\n \n _legend_kw_doc_base = \"\"\"\n bbox_to_anchor : `.BboxBase`, 2-tuple, or 4-tuple of floats\n@@ -1208,6 +1217,11 @@ class Legend(Artist):\n         \"\"\"Return ``True`` if the legend is draggable, ``False`` otherwise.\"\"\"\n         return self._draggable is not None\n \n+    def __setstate__(self, state):\n+        self.__dict__.update(state)\n+        if self._draggable:\n+            self._draggable.legend = self\n+\n \n # Helper functions to parse legend arguments for both `figure.legend` and\n # `axes.legend`:", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "matplotlib__matplotlib-25332", "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -183,10 +183,24 @@ class FigureBase(Artist):\n         self._supxlabel = None\n         self._supylabel = None\n \n+        class PicklableGrouper:\n+            def __init__(self):\n+                self._mapping = {}\n+\n+            def join(self, a, b):\n+                group_a = self._mapping.get(a, {a})\n+                group_b = self._mapping.get(b, {b})\n+                union = group_a | group_b\n+                for item in union:\n+                    self._mapping[item] = union\n+\n+            def get_siblings(self, a):\n+                return self._mapping.get(a, {a})\n+\n         # groupers to keep track of x and y labels we want to align.\n         # see self.align_xlabels and self.align_ylabels and\n         # axis._get_tick_boxes_siblings\n-        self._align_label_groups = {\"x\": cbook.Grouper(), \"y\": cbook.Grouper()}\n+        self._align_label_groups = {\"x\": PicklableGrouper(), \"y\": PicklableGrouper()}\n \n         self.figure = self\n         self._localaxes = []  # track all axes\n@@ -1380,17 +1394,11 @@ default: %(va)s\n             _log.debug(' Working on: %s', ax.get_xlabel())\n             rowspan = ax.get_subplotspec().rowspan\n             pos = ax.xaxis.get_label_position()  # top or bottom\n-            # Search through other axes for label positions that are same as\n-            # this one and that share the appropriate row number.\n-            # Add to a grouper associated with each axes of siblings.\n-            # This list is inspected in `axis.draw` by\n-            # `axis._update_label_position`.\n             for axc in axs:\n                 if axc.xaxis.get_label_position() == pos:\n                     rowspanc = axc.get_subplotspec().rowspan\n                     if (pos == 'top' and rowspan.start == rowspanc.start or\n                             pos == 'bottom' and rowspan.stop == rowspanc.stop):\n-                        # grouper for groups of xlabels to align\n                         self._align_label_groups['x'].join(ax, axc)\n \n     def align_ylabels(self, axs=None):\n@@ -1440,17 +1448,11 @@ default: %(va)s\n             _log.debug(' Working on: %s', ax.get_ylabel())\n             colspan = ax.get_subplotspec().colspan\n             pos = ax.yaxis.get_label_position()  # left or right\n-            # Search through other axes for label positions that are same as\n-            # this one and that share the appropriate column number.\n-            # Add to a list associated with each axes of siblings.\n-            # This list is inspected in `axis.draw` by\n-            # `axis._update_label_position`.\n             for axc in axs:\n                 if axc.yaxis.get_label_position() == pos:\n                     colspanc = axc.get_subplotspec().colspan\n                     if (pos == 'left' and colspan.start == colspanc.start or\n                             pos == 'right' and colspan.stop == colspanc.stop):\n-                        # grouper for groups of ylabels to align\n                         self._align_label_groups['y'].join(ax, axc)\n \n     def align_labels(self, axs=None):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "pydata__xarray-3364", "model_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -1,4 +1,5 @@\n import pandas as pd\n+import numpy as np\n \n from . import dtypes, utils\n from .alignment import align\n@@ -313,11 +314,10 @@ def _dataset_concat(\n \n         for ds in datasets:\n             absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+            for var in absent_merge_vars:\n+                for ds in datasets:\n+                    if var not in ds.variables:\n+                        ds[var] = Variable(dims=dim, data=np.full(dims_sizes[dim], fill_value))\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "pydata__xarray-4094", "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1961,7 +1961,11 @@ class DataArray(AbstractArray, DataWithCoords):\n         # pull variables out of datarray\n         data_dict = {}\n         for k in variables:\n-            data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n+            selected = self.sel({variable_dim: k})\n+            if selected.ndim == 1:\n+                data_dict[k] = selected\n+            else:\n+                data_dict[k] = selected.squeeze(drop=True)\n \n         # unstacked dataset\n         return Dataset(data_dict)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "pylint-dev__pylint-7993", "model_patch": "diff --git a/pylint/reporters/text.py b/pylint/reporters/text.py\n--- a/pylint/reporters/text.py\n+++ b/pylint/reporters/text.py\n@@ -182,7 +182,7 @@ class TextReporter(BaseReporter):\n                     f\"Don't recognize the argument '{argument[0]}' in the --msg-template. \"\n                     \"Are you sure it is supported on the current version of pylint?\"\n                 )\n-                template = re.sub(r\"\\{\" + argument[0] + r\"(:.*?)?\\}\", \"\", template)\n+                template = re.sub(r\"\\{\" + re.escape(argument[0]) + r\"(:.*?)?\\}\", \"\", template)\n         self._fixed_template = template\n \n     def write_message(self, msg: Message) -> None:", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "pytest-dev__pytest-8365", "model_patch": "diff --git a/src/_pytest/tmpdir.py b/src/_pytest/tmpdir.py\n--- a/src/_pytest/tmpdir.py\n+++ b/src/_pytest/tmpdir.py\n@@ -149,12 +149,13 @@ class TempdirFactory:\n \n \n def get_user() -> Optional[str]:\n-    \"\"\"Return the current user name, or None if getuser() does not work\n-    in the current environment (see #1010).\"\"\"\n+    \"\"\"Return the current user name, sanitized for use in directory names, \n+    or None if getuser() does not work in the current environment (see #1010).\"\"\"\n     import getpass\n \n     try:\n-        return getpass.getuser()\n+        user = getpass.getuser()\n+        return re.sub(r'[<>:\"/\\\\|?*]', '_', user)\n     except (ImportError, KeyError):\n         return None", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "pytest-dev__pytest-9359", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -887,7 +887,7 @@ class AssertionRewriter(ast.NodeVisitor):\n             # Failed\n             if assert_.msg:\n                 assertmsg = self.helper(\"_format_assertmsg\", assert_.msg)\n-                gluestr = \"\\n>assert \"\n+                gluestr = \"assert \"\n             else:\n                 assertmsg = ast.Str(\"\")\n                 gluestr = \"assert \"\n@@ -936,7 +936,7 @@ class AssertionRewriter(ast.NodeVisitor):\n             self.statements.append(ast.If(negation, body, []))\n             if assert_.msg:\n                 assertmsg = self.helper(\"_format_assertmsg\", assert_.msg)\n-                explanation = \"\\n>assert \" + explanation\n+                explanation = \"assert \" + explanation\n             else:\n                 assertmsg = ast.Str(\"\")\n                 explanation = \"assert \" + explanation", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "scikit-learn__scikit-learn-10508", "model_patch": "diff --git a/sklearn/preprocessing/label.py b/sklearn/preprocessing/label.py\n--- a/sklearn/preprocessing/label.py\n+++ b/sklearn/preprocessing/label.py\n@@ -127,6 +127,9 @@ class LabelEncoder(BaseEstimator, TransformerMixin):\n         check_is_fitted(self, 'classes_')\n         y = column_or_1d(y, warn=True)\n \n+        if len(y) == 0:\n+            return np.array([], dtype=self.classes_.dtype)\n+\n         classes = np.unique(y)\n         if len(np.intersect1d(classes, self.classes_)) < len(classes):\n             diff = np.setdiff1d(classes, self.classes_)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "scikit-learn__scikit-learn-14087", "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -2180,8 +2180,9 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,\n                 best_indices_C = best_indices % len(self.Cs_)\n                 self.C_.append(np.mean(self.Cs_[best_indices_C]))\n \n-                best_indices_l1 = best_indices // len(self.Cs_)\n-                self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))\n+                if self.penalty == 'elasticnet':\n+                    best_indices_l1 = best_indices // len(self.Cs_)\n+                    self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))\n \n             if multi_class == 'multinomial':\n                 self.C_ = np.tile(self.C_, n_classes)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "scikit-learn__scikit-learn-25638", "model_patch": "diff --git a/sklearn/utils/multiclass.py b/sklearn/utils/multiclass.py\n--- a/sklearn/utils/multiclass.py\n+++ b/sklearn/utils/multiclass.py\n@@ -23,6 +23,8 @@ from ..utils._array_api import get_namespace\n def _unique_multiclass(y):\n     xp, is_array_api = get_namespace(y)\n     if hasattr(y, \"__array__\") or is_array_api:\n+        if hasattr(y, \"dtype\") and y.dtype.name in [\"Int64\", \"Float64\", \"boolean\"]:\n+            y = y.astype(y.dtype.name.lower())\n         return xp.unique_values(xp.asarray(y))\n     else:\n         return set(y)\n@@ -78,6 +80,13 @@ def unique_labels(*ys):\n         raise ValueError(\"No argument has been passed.\")\n     # Check that we don't mix label format\n \n+    ys = [\n+        y.astype(y.dtype.name.lower())\n+        if hasattr(y, \"dtype\") and y.dtype.name in [\"Int64\", \"Float64\", \"boolean\"]\n+        else y\n+        for y in ys\n+    ]\n+\n     ys_types = set(type_of_target(x) for x in ys)\n     if ys_types == {\"binary\", \"multiclass\"}:\n         ys_types = {\"multiclass\"}\n@@ -86,7 +95,6 @@ def unique_labels(*ys):\n         raise ValueError(\"Mix type of y not allowed, got types %s\" % ys_types)\n \n     label_type = ys_types.pop()\n-\n     # Check consistency for the indicator format\n     if (\n         label_type == \"multilabel-indicator\"", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "scikit-learn__scikit-learn-25747", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1280,11 +1280,15 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n+            min_length = min(len(X) for X in Xs)\n+            Xs = [X.iloc[:min_length] for X in Xs]\n             return pd.concat(Xs, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\n         else:\n+            min_length = min(X.shape[0] for X in Xs)\n+            Xs = [X[:min_length] for X in Xs]\n             Xs = np.hstack(Xs)\n         return Xs", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sphinx-doc__sphinx-10325", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -112,7 +112,11 @@ def exclude_members_option(arg: Any) -> Union[object, Set[str]]:\n def inherited_members_option(arg: Any) -> Union[object, Set[str]]:\n     \"\"\"Used to convert the :members: option to auto directives.\"\"\"\n     if arg in (None, True):\n-        return 'object'\n+        return {'object'}\n+    elif isinstance(arg, str):\n+        return {arg}\n+    elif isinstance(arg, (list, tuple)):\n+        return set(arg)\n     else:\n         return arg\n \n@@ -681,16 +685,27 @@ class Documenter:\n         \"\"\"\n         def is_filtered_inherited_member(name: str, obj: Any) -> bool:\n             if inspect.isclass(self.object):\n-                for cls in self.object.__mro__:\n-                    if cls.__name__ == self.options.inherited_members and cls != self.object:\n-                        # given member is a member of specified *super class*\n-                        return True\n-                    elif name in cls.__dict__:\n-                        return False\n-                    elif name in self.get_attr(cls, '__annotations__', {}):\n-                        return False\n-                    elif isinstance(obj, ObjectMember) and obj.class_ is cls:\n-                        return False\n+                inherited_members = self.options.inherited_members\n+                if isinstance(inherited_members, set):\n+                    for cls in self.object.__mro__:\n+                        if cls.__name__ in inherited_members and cls != self.object:\n+                            return True\n+                        elif name in cls.__dict__:\n+                            return False\n+                        elif name in self.get_attr(cls, '__annotations__', {}):\n+                            return False\n+                        elif isinstance(obj, ObjectMember) and obj.class_ is cls:\n+                            return False\n+                else:\n+                    for cls in self.object.__mro__:\n+                        if cls.__name__ == inherited_members and cls != self.object:\n+                            return True\n+                        elif name in cls.__dict__:\n+                            return False\n+                        elif name in self.get_attr(cls, '__annotations__', {}):\n+                            return False\n+                        elif isinstance(obj, ObjectMember) and obj.class_ is cls:\n+                            return False\n \n             return False\n \n@@ -1700,7 +1715,6 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n         if not want_all:\n             if not self.options.members:\n                 return False, []  # type: ignore\n-            # specific members given\n             selected = []\n             for name in self.options.members:  # type: str\n                 if name in members:\n@@ -1710,7 +1724,11 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n                                    (name, self.fullname), type='autodoc')\n             return False, selected\n         elif self.options.inherited_members:\n-            return False, list(members.values())\n+            inherited_members = self.options.inherited_members\n+            if isinstance(inherited_members, set):\n+                return False, [m for m in members.values() if m.class_.__name__ not in inherited_members]\n+            else:\n+                return False, list(members.values())\n         else:\n             return False, [m for m in members.values() if m.class_ == self.object]", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sphinx-doc__sphinx-10451", "model_patch": "diff --git a/sphinx/ext/autodoc/typehints.py b/sphinx/ext/autodoc/typehints.py\n--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -47,7 +47,6 @@ def merge_typehints(app: Sphinx, domain: str, objtype: str, contentnode: Element\n         else:\n             fullname = signature['fullname']\n     except KeyError:\n-        # signature node does not have valid context info for the target object\n         return\n \n     annotations = app.env.temp_data.get('annotations', {})\n@@ -72,6 +71,16 @@ def merge_typehints(app: Sphinx, domain: str, objtype: str, contentnode: Element\n                     field_list, annotations[fullname], force_rtype=False\n                 )\n \n+        # Remove duplicated *args and **kwargs\n+        for field_list in field_lists:\n+            fields_to_remove = []\n+            for field in field_list:\n+                field_name = field[0].astext()\n+                if field_name in ('param *args', 'param **kwargs', 'type *args', 'type **kwargs'):\n+                    fields_to_remove.append(field)\n+            for field in fields_to_remove:\n+                field_list.remove(field)\n+\n \n def insert_field_list(node: Element) -> nodes.field_list:\n     field_list = nodes.field_list()\n@@ -95,11 +104,9 @@ def modify_field_list(node: nodes.field_list, annotations: Dict[str, str],\n         parts = re.split(' +', field_name)\n         if parts[0] == 'param':\n             if len(parts) == 2:\n-                # :param xxx:\n                 arg = arguments.setdefault(parts[1], {})\n                 arg['param'] = True\n             elif len(parts) > 2:\n-                # :param xxx yyy:\n                 name = ' '.join(parts[2:])\n                 arg = arguments.setdefault(name, {})\n                 arg['param'] = True\n@@ -116,12 +123,12 @@ def modify_field_list(node: nodes.field_list, annotations: Dict[str, str],\n             continue\n \n         arg = arguments.get(name, {})\n-        if not arg.get('type'):\n+        if not arg.get('type') and name not in ('*args', '**kwargs'):\n             field = nodes.field()\n             field += nodes.field_name('', 'type ' + name)\n             field += nodes.field_body('', nodes.paragraph('', annotation))\n             node += field\n-        if not arg.get('param'):\n+        if not arg.get('param') and name not in ('*args', '**kwargs'):\n             field = nodes.field()\n             field += nodes.field_name('', 'param ' + name)\n             field += nodes.field_body('', nodes.paragraph('', ''))\n@@ -168,7 +175,7 @@ def augment_descriptions_with_types(\n \n     # Add 'type' for parameters with a description but no declared type.\n     for name in annotations:\n-        if name in ('return', 'returns'):\n+        if name in ('return', 'returns', '*args', '**kwargs'):\n             continue\n         if name in has_description and name not in has_type:\n             field = nodes.field()", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sphinx-doc__sphinx-11445", "model_patch": "diff --git a/sphinx/util/rst.py b/sphinx/util/rst.py\n--- a/sphinx/util/rst.py\n+++ b/sphinx/util/rst.py\n@@ -79,23 +79,32 @@ def prepend_prolog(content: StringList, prolog: str) -> None:\n     \"\"\"Prepend a string to content body as prolog.\"\"\"\n     if prolog:\n         pos = 0\n-        for line in content:\n+        heading_found = False\n+        for i, line in enumerate(content):\n+            if re.match(r'^\\s*={3,}\\s*$', line) or re.match(r'^\\s*-{3,}\\s*$', line):\n+                heading_found = True\n+                pos = i + 1\n+                break\n             if docinfo_re.match(line):\n                 pos += 1\n             else:\n                 break\n \n-        if pos > 0:\n-            # insert a blank line after docinfo\n+        if pos > 0 and not heading_found:\n             content.insert(pos, '', '<generated>', 0)\n             pos += 1\n \n-        # insert prolog (after docinfo if exists)\n         for lineno, line in enumerate(prolog.splitlines()):\n             content.insert(pos + lineno, line, '<rst_prolog>', lineno)\n \n         content.insert(pos + lineno + 1, '', '<generated>', 0)\n \n+        if heading_found:\n+            for i, line in enumerate(content):\n+                if re.match(r'^\\s*:\\w+:`.*`\\s*$', line):\n+                    content.pop(i)\n+                    break\n+\n \n def append_epilog(content: StringList, epilog: str) -> None:\n     \"\"\"Append a string to content body as epilog.\"\"\"", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sphinx-doc__sphinx-8435", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -2093,7 +2093,7 @@ class AttributeDocumenter(DocstringStripSignatureMixin, ClassLevelDocumenter):\n         if not self.options.annotation:\n             # obtain type annotation for this attribute\n             try:\n-                annotations = get_type_hints(self.parent)\n+                annotations = get_type_hints(self.parent, globalns=None, localns=self.config.autodoc_type_aliases)\n             except NameError:\n                 # Failed to evaluate ForwardRef (maybe TYPE_CHECKING)\n                 annotations = safe_getattr(self.parent, '__annotations__', {})", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-13043", "model_patch": "diff --git a/sympy/integrals/intpoly.py b/sympy/integrals/intpoly.py\n--- a/sympy/integrals/intpoly.py\n+++ b/sympy/integrals/intpoly.py\n@@ -569,7 +569,7 @@ def decompose(expr, separate=False):\n             degrees = [(sum(degree_list(monom, *symbols)), monom)\n                        for monom in expr.args]\n             if separate:\n-                return [monom[1] for monom in degrees]\n+                return [monom[1] for monom in sorted(degrees)]\n             else:\n                 for monom in degrees:\n                     degree, term = monom\n@@ -593,7 +593,7 @@ def decompose(expr, separate=False):\n         poly_dict[0] = expr\n \n     if separate:\n-        return list(poly_dict.values())\n+        return [poly_dict[key] for key in sorted(poly_dict)]\n     return poly_dict", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-13971", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1655,9 +1655,9 @@ def _print_SeqFormula(self, s):\n         else:\n             printset = tuple(s)\n \n-        return (r\"\\left\\[\"\n+        return (r\"[\"\n               + r\", \".join(self._print(el) for el in printset)\n-              + r\"\\right\\]\")\n+              + r\"]\")\n \n     _print_SeqPer = _print_SeqFormula\n     _print_SeqAdd = _print_SeqFormula", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-14396", "model_patch": "diff --git a/sympy/polys/polyoptions.py b/sympy/polys/polyoptions.py\n--- a/sympy/polys/polyoptions.py\n+++ b/sympy/polys/polyoptions.py\n@@ -480,7 +480,11 @@ def preprocess(cls, domain):\n                 gens = list(map(sympify, r.groups()[1].split(',')))\n                 return sympy.polys.domains.QQ.algebraic_field(*gens)\n \n-        raise OptionError('expected a valid domain specification, got %s' % domain)\n+            if domain.startswith('RR[') and domain.endswith(']'):\n+                gens = list(map(sympify, domain[3:-1].split(',')))\n+                return sympy.polys.domains.RR.poly_ring(*gens)\n+\n+        raise OptionError('Expected a valid domain specification, but got: %s' % domain)\n \n     @classmethod\n     def postprocess(cls, options):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-15345", "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -31,7 +31,7 @@\n     \"asech\": [(lambda x: True, \"ArcSech\")],\n     \"acsch\": [(lambda x: True, \"ArcCsch\")],\n     \"conjugate\": [(lambda x: True, \"Conjugate\")],\n-\n+    \"Max\": [(lambda x: True, \"Max\")],\n }", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-16281", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -479,7 +479,6 @@ def _print_Product(self, expr):\n         vertical_chr = xobj('|', 1)\n \n         if self._use_unicode:\n-            # use unicode corners\n             horizontal_chr = xobj('-', 1)\n             corner_chr = u'\\N{BOX DRAWINGS LIGHT DOWN AND HORIZONTAL}'\n \n@@ -490,10 +489,10 @@ def _print_Product(self, expr):\n         sign_height = 0\n \n         for lim in expr.limits:\n-            width = (func_height + 2) * 5 // 3 - 2\n+            width = (func_height + 2) * 3 // 2 - 2\n             sign_lines = []\n-            sign_lines.append(corner_chr + (horizontal_chr*width) + corner_chr)\n-            for i in range(func_height + 1):\n+            sign_lines.append(horizontal_chr + (horizontal_chr*width) + horizontal_chr)\n+            for i in range(func_height):\n                 sign_lines.append(vertical_chr + (' '*width) + vertical_chr)\n \n             pretty_sign = stringPict('')\n@@ -516,7 +515,7 @@ def _print_Product(self, expr):\n \n             height = pretty_sign.height()\n             padding = stringPict('')\n-            padding = prettyForm(*padding.stack(*[' ']*(height - 1)))\n+            padding = prettyForm(*padding.stack(*[' ']*(height - 2)))\n             pretty_sign = prettyForm(*pretty_sign.right(padding))\n \n             pretty_func = prettyForm(*pretty_sign.right(pretty_func))", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-16792", "model_patch": "diff --git a/sympy/utilities/autowrap.py b/sympy/utilities/autowrap.py\n--- a/sympy/utilities/autowrap.py\n+++ b/sympy/utilities/autowrap.py\n@@ -447,6 +447,11 @@ def _prototype_arg(self, arg):\n             mtype = np_types[t]\n             return mat_dec.format(mtype=mtype, ndim=ndim, name=self._string_var(arg.name))\n         else:\n+            if isinstance(arg, (InputArgument, InOutArgument)) and arg.dimensions:\n+                self._need_numpy = True\n+                ndim = len(arg.dimensions)\n+                mtype = np_types[t]\n+                return mat_dec.format(mtype=mtype, ndim=ndim, name=self._string_var(arg.name))\n             return \"%s %s\" % (t, self._string_var(arg.name))\n \n     def _declare_arg(self, arg):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-16988", "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -1262,6 +1262,9 @@ def __new__(cls, *args, **kwargs):\n         # flatten inputs to merge intersections and iterables\n         args = _sympify(args)\n \n+        # Remove duplicates\n+        args = list(dict.fromkeys(args))\n+\n         # Reduce sets using known rules\n         if evaluate:\n             args = list(cls._new_args_filter(args))", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-19007", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -244,7 +244,7 @@ def _entry(self, i, j, **kwargs):\n                 break\n             else:\n                 j -= numcols\n-        return self.blocks[row_block, col_block][i, j]\n+        return self.blocks[row_block, col_block]._entry(i, j, **kwargs)\n \n     @property\n     def is_Identity(self):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-21612", "model_patch": "diff --git a/sympy/parsing/latex/_parse_latex_antlr.py b/sympy/parsing/latex/_parse_latex_antlr.py\n--- a/sympy/parsing/latex/_parse_latex_antlr.py\n+++ b/sympy/parsing/latex/_parse_latex_antlr.py\n@@ -140,7 +140,7 @@ def convert_mp(mp):\n     elif mp.DIV() or mp.CMD_DIV() or mp.COLON():\n         lh = convert_mp(mp_left)\n         rh = convert_mp(mp_right)\n-        return sympy.Mul(lh, sympy.Pow(rh, -1, evaluate=False), evaluate=False)\n+        return sympy.Mul(lh, sympy.Pow(sympy.Paren(rh), -1, evaluate=False), evaluate=False)\n     else:\n         if hasattr(mp, 'unary'):\n             return convert_unary(mp.unary())", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-24102", "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -586,7 +586,7 @@ def parse(self, s):\n         \"##\": lambda: [\"SlotSequence\", \"1\"],\n     }\n \n-    _literal = r\"[A-Za-z][A-Za-z0-9]*\"\n+    _literal = r\"[A-Za-z\\u0370-\\u03FF\\u1F00-\\u1FFF][A-Za-z0-9\\u0370-\\u03FF\\u1F00-\\u1FFF]*\"\n     _number = r\"(?:[0-9]+(?:\\.[0-9]*)?|\\.[0-9]+)\"\n \n     _enclosure_open = [\"(\", \"[\", \"[[\", \"{\"]", "model_name_or_path": "MoatlessToolsplusGPT4o"}
