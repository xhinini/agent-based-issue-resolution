{"instance_id": "astropy__astropy-14365", "model_patch": "diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -68,7 +68,7 @@ def _line_type(line, delimiter=None):\n     _new_re = rf\"NO({sep}NO)+\"\n     _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*)\"\n     _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\\s*(\\!(?P<comment>.*))?\\s*$\"\n-    _line_type_re = re.compile(_type_re)\n+    _line_type_re = re.compile(_type_re, re.IGNORECASE)\n     line = line.strip()\n     if not line:\n         return \"comment\"\n@@ -306,7 +306,7 @@ def _get_tables_from_qdp_file(qdp_file, input_colnames=None, delimiter=None):\n \n             values = []\n             for v in line.split(delimiter):\n-                if v == \"NO\":\n+                if v.upper() == \"NO\":\n                     values.append(np.ma.masked)\n                 else:\n                     # Understand if number is int or float", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "astropy__astropy-6938", "model_patch": "diff --git a/astropy/io/fits/fitsrec.py b/astropy/io/fits/fitsrec.py\n--- a/astropy/io/fits/fitsrec.py\n+++ b/astropy/io/fits/fitsrec.py\n@@ -1261,7 +1261,7 @@ class FITS_rec(np.recarray):\n \n         # Replace exponent separator in floating point numbers\n         if 'D' in format:\n-            output_field.replace(encode_ascii('E'), encode_ascii('D'))\n+            output_field = output_field.replace(encode_ascii('E'), encode_ascii('D'))\n \n \n def _get_recarray_field(array, key):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "astropy__astropy-7746", "model_patch": "diff --git a/astropy/wcs/wcs.py b/astropy/wcs/wcs.py\n--- a/astropy/wcs/wcs.py\n+++ b/astropy/wcs/wcs.py\n@@ -1212,6 +1212,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n         \"\"\"\n \n         def _return_list_of_arrays(axes, origin):\n+            if all(len(x) == 0 for x in axes):\n+                return [np.array([]) for _ in range(self.naxis)]\n             try:\n                 axes = np.broadcast_arrays(*axes)\n             except ValueError:\n@@ -1231,6 +1233,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n                     for i in range(output.shape[1])]\n \n         def _return_single_array(xy, origin):\n+            if xy.size == 0:\n+                return np.array([])\n             if xy.shape[-1] != self.naxis:\n                 raise ValueError(\n                     \"When providing two arguments, the array must be \"\n@@ -1241,7 +1245,6 @@ reduce these to 2 dimensions using the naxis kwarg.\n             if ra_dec_order and sky == 'output':\n                 result = self._normalize_sky(result)\n             return result\n-\n         if len(args) == 2:\n             try:\n                 xy, origin = args\n@@ -1349,6 +1352,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n     def wcs_pix2world(self, *args, **kwargs):\n         if self.wcs is None:\n             raise ValueError(\"No basic WCS settings were created.\")\n+        if all(isinstance(arg, (list, np.ndarray)) and len(arg) == 0 for arg in args[:-1]):\n+            return [np.array([]) for _ in range(self.naxis)]\n         return self._array_converter(\n             lambda xy, o: self.wcs.p2s(xy, o)['world'],\n             'output', *args, **kwargs)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-11742", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -257,6 +257,7 @@ def is_value(value, accept_promise=True):\n                 )\n             ]\n \n+        choice_max_length: int = 0  # type inference added for clarity\n         # Expect [group_name, [value, display]]\n         for choices_group in self.choices:\n             try:\n@@ -270,16 +271,32 @@ def is_value(value, accept_promise=True):\n                     for value, human_name in group_choices\n                 ):\n                     break\n+                if self.max_length is not None and group_choices:\n+                    choice_max_length = max(\n+                        choice_max_length,\n+                        *(len(value) for value, _ in group_choices if isinstance(value, str)),\n+                    )\n             except (TypeError, ValueError):\n                 # No groups, choices in the form [value, display]\n                 value, human_name = group_name, group_choices\n                 if not is_value(value) or not is_value(human_name):\n                     break\n+                if self.max_length is not None and isinstance(value, str):\n+                    choice_max_length = max(choice_max_length, len(value))\n \n             # Special case: choices=['ab']\n             if isinstance(choices_group, str):\n                 break\n         else:\n+            if self.max_length is not None and choice_max_length > self.max_length:\n+                return [\n+                    checks.Error(\n+                        \"'max_length' is too small to fit the longest value \"\n+                        \"in 'choices' (%d characters).\" % choice_max_length,\n+                        obj=self,\n+                        id='fields.E009',\n+                    ),\n+                ]\n             return []\n \n         return [", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-11910", "model_patch": "diff --git a/django/db/migrations/operations/fields.py b/django/db/migrations/operations/fields.py\n--- a/django/db/migrations/operations/fields.py\n+++ b/django/db/migrations/operations/fields.py\n@@ -228,8 +228,15 @@ class AlterField(FieldOperation):\n             for n, f in\n             state.models[app_label, self.model_name_lower].fields\n         ]\n-        # TODO: investigate if old relational fields must be reloaded or if it's\n-        # sufficient if the new field is (#27737).\n+        # Update to_fields in related models to refer to the new field name\n+        for (model_app_label, model_name), model_state in state.models.items():\n+            for index, (name, f) in enumerate(model_state.fields):\n+                if f.remote_field and f.remote_field.model == state.models[app_label, self.model_name_lower].name:\n+                    if f.to_fields:\n+                        f.to_fields = tuple([\n+                            self.name if to_field_name == self.name else to_field_name\n+                            for to_field_name in f.to_fields\n+                        ])\n         # Delay rendering of relationships if it's not a relational field and\n         # not referenced by a foreign key.\n         delay = (\n@@ -237,7 +244,6 @@ class AlterField(FieldOperation):\n             not is_referenced_by_foreign_key(state, self.model_name_lower, self.field, self.name)\n         )\n         state.reload_model(app_label, self.model_name_lower, delay=delay)\n-\n     def database_forwards(self, app_label, schema_editor, from_state, to_state):\n         to_model = to_state.apps.get_model(app_label, self.model_name)\n         if self.allow_migrate_model(schema_editor.connection.alias, to_model):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-12308", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -398,6 +398,8 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+    elif isinstance(field, models.JSONField):\n+        return field.formfield().prepare_value(value)\n     else:\n         return display_for_value(value, empty_value_display)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-12747", "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -408,7 +408,8 @@ def delete(self):\n             # fast deletes\n             for qs in self.fast_deletes:\n                 count = qs._raw_delete(using=self.using)\n-                deleted_counter[qs.model._meta.label] += count\n+                if count > 0:\n+                    deleted_counter[qs.model._meta.label] += count\n \n             # update fields\n             for model, instances_for_fieldvalues in self.field_updates.items():\n@@ -426,7 +427,8 @@ def delete(self):\n                 query = sql.DeleteQuery(model)\n                 pk_list = [obj.pk for obj in instances]\n                 count = query.delete_batch(pk_list, self.using)\n-                deleted_counter[model._meta.label] += count\n+                if count > 0:\n+                    deleted_counter[model._meta.label] += count\n \n                 if not model._meta.auto_created:\n                     for obj in instances:", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-14534", "model_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -277,7 +277,7 @@ class BoundWidget:\n \n     @property\n     def id_for_label(self):\n-        return 'id_%s_%s' % (self.data['name'], self.data['index'])\n+        return self.data['attrs']['id']\n \n     @property\n     def choice_label(self):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-14997", "model_patch": "diff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -278,6 +278,11 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         body_copy['__module__'] = model.__module__\n         new_model = type('New%s' % model._meta.object_name, model.__bases__, body_copy)\n \n+        # Remove unique constraints before remaking the table\n+        for constraint in constraints:\n+            if isinstance(constraint, UniqueConstraint):\n+                self.execute(self._delete_constraint_sql(model, constraint))\n+\n         # Create a new table with the updated schema.\n         self.create_model(new_model)\n \n@@ -298,10 +303,16 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n             disable_constraints=False,\n         )\n \n+        # Re-add unique constraints after remaking the table\n+        for constraint in constraints:\n+            if isinstance(constraint, UniqueConstraint):\n+                self.execute(self._create_constraint_sql(model, constraint))\n+\n         # Run deferred SQL on correct table\n-        for sql in self.deferred_sql:\n-            self.execute(sql)\n+        deferred_sql = self.deferred_sql\n         self.deferred_sql = []\n+        for sql in deferred_sql:\n+            self.execute(sql)\n         # Fix any PK-removed field\n         if restore_pk_field:\n             restore_pk_field.primary_key = True", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "django__django-16910", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -779,7 +779,13 @@ def _get_only_select_mask(self, opts, mask, select_mask=None):\n         # Only include fields mentioned in the mask.\n         for field_name, field_mask in mask.items():\n             field = opts.get_field(field_name)\n-            field_select_mask = select_mask.setdefault(field, {})\n+            # Ensure the correct field is used from reverse relationships\n+            # for clarity in select_mask handling.\n+            if field in opts.related_objects:\n+                field_key = field.field\n+            else:\n+                field_key = field\n+            field_select_mask = select_mask.setdefault(field_key, {})\n             if field_mask:\n                 if not field.is_relation:\n                     raise FieldError(next(iter(field_mask)))", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "matplotlib__matplotlib-25311", "model_patch": "diff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1505,7 +1505,6 @@ def __init__(self, ref_artist, use_blit=False):\n         if not ref_artist.pickable():\n             ref_artist.set_picker(True)\n         self.got_artist = False\n-        self.canvas = self.ref_artist.figure.canvas\n         self._use_blit = use_blit and self.canvas.supports_blit\n         self.cids = [\n             self.canvas.callbacks._connect_picklable(\n@@ -1514,6 +1513,9 @@ def __init__(self, ref_artist, use_blit=False):\n                 'button_release_event', self.on_release),\n         ]\n \n+    # A property to ensure that we maintain picklability.\n+    canvas = property(lambda self: self.ref_artist.figure.canvas)\n+    # This avoids having a direct attribute, which would break pickling.\n     def on_motion(self, evt):\n         if self._check_still_parented() and self.got_artist:\n             dx = evt.x - self.mouse_x", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "matplotlib__matplotlib-25332", "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -183,10 +183,24 @@ class FigureBase(Artist):\n         self._supxlabel = None\n         self._supylabel = None\n \n+        class PicklableGrouper:\n+            def __init__(self):\n+                self._mapping = {}\n+\n+            def join(self, a, b):\n+                group_a = self._mapping.get(a, {a})\n+                group_b = self._mapping.get(b, {b})\n+                union = group_a | group_b\n+                for item in union:\n+                    self._mapping[item] = union\n+\n+            def get_siblings(self, a):\n+                return self._mapping.get(a, {a})\n+\n         # groupers to keep track of x and y labels we want to align.\n         # see self.align_xlabels and self.align_ylabels and\n         # axis._get_tick_boxes_siblings\n-        self._align_label_groups = {\"x\": cbook.Grouper(), \"y\": cbook.Grouper()}\n+        self._align_label_groups = {\"x\": PicklableGrouper(), \"y\": PicklableGrouper()}\n \n         self.figure = self\n         self._localaxes = []  # track all axes\n@@ -1380,17 +1394,11 @@ default: %(va)s\n             _log.debug(' Working on: %s', ax.get_xlabel())\n             rowspan = ax.get_subplotspec().rowspan\n             pos = ax.xaxis.get_label_position()  # top or bottom\n-            # Search through other axes for label positions that are same as\n-            # this one and that share the appropriate row number.\n-            # Add to a grouper associated with each axes of siblings.\n-            # This list is inspected in `axis.draw` by\n-            # `axis._update_label_position`.\n             for axc in axs:\n                 if axc.xaxis.get_label_position() == pos:\n                     rowspanc = axc.get_subplotspec().rowspan\n                     if (pos == 'top' and rowspan.start == rowspanc.start or\n                             pos == 'bottom' and rowspan.stop == rowspanc.stop):\n-                        # grouper for groups of xlabels to align\n                         self._align_label_groups['x'].join(ax, axc)\n \n     def align_ylabels(self, axs=None):\n@@ -1440,17 +1448,11 @@ default: %(va)s\n             _log.debug(' Working on: %s', ax.get_ylabel())\n             colspan = ax.get_subplotspec().colspan\n             pos = ax.yaxis.get_label_position()  # left or right\n-            # Search through other axes for label positions that are same as\n-            # this one and that share the appropriate column number.\n-            # Add to a list associated with each axes of siblings.\n-            # This list is inspected in `axis.draw` by\n-            # `axis._update_label_position`.\n             for axc in axs:\n                 if axc.yaxis.get_label_position() == pos:\n                     colspanc = axc.get_subplotspec().colspan\n                     if (pos == 'left' and colspan.start == colspanc.start or\n                             pos == 'right' and colspan.stop == colspanc.stop):\n-                        # grouper for groups of ylabels to align\n                         self._align_label_groups['y'].join(ax, axc)\n \n     def align_labels(self, axs=None):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "pydata__xarray-3364", "model_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -1,4 +1,5 @@\n import pandas as pd\n+import numpy as np\n \n from . import dtypes, utils\n from .alignment import align\n@@ -313,11 +314,10 @@ def _dataset_concat(\n \n         for ds in datasets:\n             absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+            for var in absent_merge_vars:\n+                for ds in datasets:\n+                    if var not in ds.variables:\n+                        ds[var] = Variable(dims=dim, data=np.full(dims_sizes[dim], fill_value))\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "pydata__xarray-4094", "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1961,7 +1961,11 @@ class DataArray(AbstractArray, DataWithCoords):\n         # pull variables out of datarray\n         data_dict = {}\n         for k in variables:\n-            data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n+            selected = self.sel({variable_dim: k})\n+            if selected.ndim == 1:\n+                data_dict[k] = selected\n+            else:\n+                data_dict[k] = selected.squeeze(drop=True)\n \n         # unstacked dataset\n         return Dataset(data_dict)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "pylint-dev__pylint-7993", "model_patch": "diff --git a/pylint/reporters/text.py b/pylint/reporters/text.py\n--- a/pylint/reporters/text.py\n+++ b/pylint/reporters/text.py\n@@ -175,7 +175,7 @@ def on_set_current_module(self, module: str, filepath: str | None) -> None:\n         self._template = template\n \n         # Check to see if all parameters in the template are attributes of the Message\n-        arguments = re.findall(r\"\\{(.+?)(:.*)?\\}\", template)\n+        arguments = re.findall(r\"\\{(\\w+?)(:.*)?\\}\", template)\n         for argument in arguments:\n             if argument[0] not in MESSAGE_FIELDS:\n                 warnings.warn(", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "pytest-dev__pytest-8365", "model_patch": "diff --git a/src/_pytest/tmpdir.py b/src/_pytest/tmpdir.py\n--- a/src/_pytest/tmpdir.py\n+++ b/src/_pytest/tmpdir.py\n@@ -115,7 +115,12 @@ def getbasetemp(self) -> Path:\n             # use a sub-directory in the temproot to speed-up\n             # make_numbered_dir() call\n             rootdir = temproot.joinpath(f\"pytest-of-{user}\")\n-            rootdir.mkdir(exist_ok=True)\n+            try:\n+                rootdir.mkdir(exist_ok=True)\n+            except OSError:\n+                # getuser() likely returned illegal characters for the platform, fallback to \"unknown\"\n+                rootdir = temproot.joinpath(\"pytest-of-unknown\")\n+                rootdir.mkdir(exist_ok=True)\n             basetemp = make_numbered_dir_with_cleanup(\n                 prefix=\"pytest-\", root=rootdir, keep=3, lock_timeout=LOCK_TIMEOUT\n             )", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "pytest-dev__pytest-9359", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -887,7 +887,7 @@ class AssertionRewriter(ast.NodeVisitor):\n             # Failed\n             if assert_.msg:\n                 assertmsg = self.helper(\"_format_assertmsg\", assert_.msg)\n-                gluestr = \"\\n>assert \"\n+                gluestr = \"assert \"\n             else:\n                 assertmsg = ast.Str(\"\")\n                 gluestr = \"assert \"\n@@ -936,7 +936,7 @@ class AssertionRewriter(ast.NodeVisitor):\n             self.statements.append(ast.If(negation, body, []))\n             if assert_.msg:\n                 assertmsg = self.helper(\"_format_assertmsg\", assert_.msg)\n-                explanation = \"\\n>assert \" + explanation\n+                explanation = \"assert \" + explanation\n             else:\n                 assertmsg = ast.Str(\"\")\n                 explanation = \"assert \" + explanation", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "scikit-learn__scikit-learn-10508", "model_patch": "diff --git a/sklearn/preprocessing/label.py b/sklearn/preprocessing/label.py\n--- a/sklearn/preprocessing/label.py\n+++ b/sklearn/preprocessing/label.py\n@@ -127,6 +127,9 @@ class LabelEncoder(BaseEstimator, TransformerMixin):\n         check_is_fitted(self, 'classes_')\n         y = column_or_1d(y, warn=True)\n \n+        if len(y) == 0:\n+            return np.array([], dtype=self.classes_.dtype)\n+\n         classes = np.unique(y)\n         if len(np.intersect1d(classes, self.classes_)) < len(classes):\n             diff = np.setdiff1d(classes, self.classes_)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "scikit-learn__scikit-learn-14087", "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -2170,7 +2170,7 @@ def fit(self, X, y, sample_weight=None):\n                 # Take the best scores across every fold and the average of\n                 # all coefficients corresponding to the best scores.\n                 best_indices = np.argmax(scores, axis=1)\n-                if self.multi_class == 'ovr':\n+                if multi_class == 'ovr':\n                     w = np.mean([coefs_paths[i, best_indices[i], :]\n                                  for i in range(len(folds))], axis=0)\n                 else:\n@@ -2180,8 +2180,11 @@ def fit(self, X, y, sample_weight=None):\n                 best_indices_C = best_indices % len(self.Cs_)\n                 self.C_.append(np.mean(self.Cs_[best_indices_C]))\n \n-                best_indices_l1 = best_indices // len(self.Cs_)\n-                self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))\n+                if self.penalty == 'elasticnet':\n+                    best_indices_l1 = best_indices // len(self.Cs_)\n+                    self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))\n+                else:\n+                    self.l1_ratio_.append(None)\n \n             if multi_class == 'multinomial':\n                 self.C_ = np.tile(self.C_, n_classes)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "scikit-learn__scikit-learn-25638", "model_patch": "diff --git a/sklearn/utils/multiclass.py b/sklearn/utils/multiclass.py\n--- a/sklearn/utils/multiclass.py\n+++ b/sklearn/utils/multiclass.py\n@@ -23,6 +23,8 @@ from ..utils._array_api import get_namespace\n def _unique_multiclass(y):\n     xp, is_array_api = get_namespace(y)\n     if hasattr(y, \"__array__\") or is_array_api:\n+        if hasattr(y, \"dtype\") and y.dtype.name in [\"Int64\", \"Float64\", \"boolean\"]:\n+            y = y.astype(y.dtype.name.lower())\n         return xp.unique_values(xp.asarray(y))\n     else:\n         return set(y)\n@@ -78,6 +80,13 @@ def unique_labels(*ys):\n         raise ValueError(\"No argument has been passed.\")\n     # Check that we don't mix label format\n \n+    ys = [\n+        y.astype(y.dtype.name.lower())\n+        if hasattr(y, \"dtype\") and y.dtype.name in [\"Int64\", \"Float64\", \"boolean\"]\n+        else y\n+        for y in ys\n+    ]\n+\n     ys_types = set(type_of_target(x) for x in ys)\n     if ys_types == {\"binary\", \"multiclass\"}:\n         ys_types = {\"multiclass\"}\n@@ -86,7 +95,6 @@ def unique_labels(*ys):\n         raise ValueError(\"Mix type of y not allowed, got types %s\" % ys_types)\n \n     label_type = ys_types.pop()\n-\n     # Check consistency for the indicator format\n     if (\n         label_type == \"multilabel-indicator\"", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "scikit-learn__scikit-learn-25747", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1280,11 +1280,15 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n+            min_length = min(len(X) for X in Xs)\n+            Xs = [X.iloc[:min_length] for X in Xs]\n             return pd.concat(Xs, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\n         else:\n+            min_length = min(X.shape[0] for X in Xs)\n+            Xs = [X[:min_length] for X in Xs]\n             Xs = np.hstack(Xs)\n         return Xs", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sphinx-doc__sphinx-10325", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -109,12 +109,14 @@ def exclude_members_option(arg: Any) -> Union[object, Set[str]]:\n     return {x.strip() for x in arg.split(',') if x.strip()}\n \n \n-def inherited_members_option(arg: Any) -> Union[object, Set[str]]:\n+def inherited_members_option(arg: Any) -> Set[str]:\n     \"\"\"Used to convert the :members: option to auto directives.\"\"\"\n     if arg in (None, True):\n-        return 'object'\n+        return {'object'}\n+    elif arg:\n+        return set(x.strip() for x in arg.split(','))\n     else:\n-        return arg\n+        return set()\n \n \n def member_order_option(arg: Any) -> Optional[str]:\n@@ -680,9 +682,11 @@ def filter_members(self, members: ObjectMembers, want_all: bool\n         ``autodoc-skip-member`` event.\n         \"\"\"\n         def is_filtered_inherited_member(name: str, obj: Any) -> bool:\n+            inherited_members = self.options.inherited_members or set()\n+\n             if inspect.isclass(self.object):\n                 for cls in self.object.__mro__:\n-                    if cls.__name__ == self.options.inherited_members and cls != self.object:\n+                    if cls.__name__ in inherited_members and cls != self.object:\n                         # given member is a member of specified *super class*\n                         return True\n                     elif name in cls.__dict__:", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sphinx-doc__sphinx-10451", "model_patch": "diff --git a/sphinx/ext/autodoc/typehints.py b/sphinx/ext/autodoc/typehints.py\n--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -47,7 +47,6 @@ def merge_typehints(app: Sphinx, domain: str, objtype: str, contentnode: Element\n         else:\n             fullname = signature['fullname']\n     except KeyError:\n-        # signature node does not have valid context info for the target object\n         return\n \n     annotations = app.env.temp_data.get('annotations', {})\n@@ -72,6 +71,16 @@ def merge_typehints(app: Sphinx, domain: str, objtype: str, contentnode: Element\n                     field_list, annotations[fullname], force_rtype=False\n                 )\n \n+        # Remove duplicated *args and **kwargs\n+        for field_list in field_lists:\n+            fields_to_remove = []\n+            for field in field_list:\n+                field_name = field[0].astext()\n+                if field_name in ('param *args', 'param **kwargs', 'type *args', 'type **kwargs'):\n+                    fields_to_remove.append(field)\n+            for field in fields_to_remove:\n+                field_list.remove(field)\n+\n \n def insert_field_list(node: Element) -> nodes.field_list:\n     field_list = nodes.field_list()\n@@ -95,11 +104,9 @@ def modify_field_list(node: nodes.field_list, annotations: Dict[str, str],\n         parts = re.split(' +', field_name)\n         if parts[0] == 'param':\n             if len(parts) == 2:\n-                # :param xxx:\n                 arg = arguments.setdefault(parts[1], {})\n                 arg['param'] = True\n             elif len(parts) > 2:\n-                # :param xxx yyy:\n                 name = ' '.join(parts[2:])\n                 arg = arguments.setdefault(name, {})\n                 arg['param'] = True\n@@ -116,12 +123,12 @@ def modify_field_list(node: nodes.field_list, annotations: Dict[str, str],\n             continue\n \n         arg = arguments.get(name, {})\n-        if not arg.get('type'):\n+        if not arg.get('type') and name not in ('*args', '**kwargs'):\n             field = nodes.field()\n             field += nodes.field_name('', 'type ' + name)\n             field += nodes.field_body('', nodes.paragraph('', annotation))\n             node += field\n-        if not arg.get('param'):\n+        if not arg.get('param') and name not in ('*args', '**kwargs'):\n             field = nodes.field()\n             field += nodes.field_name('', 'param ' + name)\n             field += nodes.field_body('', nodes.paragraph('', ''))\n@@ -168,7 +175,7 @@ def augment_descriptions_with_types(\n \n     # Add 'type' for parameters with a description but no declared type.\n     for name in annotations:\n-        if name in ('return', 'returns'):\n+        if name in ('return', 'returns', '*args', '**kwargs'):\n             continue\n         if name in has_description and name not in has_type:\n             field = nodes.field()", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sphinx-doc__sphinx-11445", "model_patch": "diff --git a/sphinx/util/rst.py b/sphinx/util/rst.py\n--- a/sphinx/util/rst.py\n+++ b/sphinx/util/rst.py\n@@ -79,23 +79,32 @@ def prepend_prolog(content: StringList, prolog: str) -> None:\n     \"\"\"Prepend a string to content body as prolog.\"\"\"\n     if prolog:\n         pos = 0\n-        for line in content:\n+        heading_found = False\n+        for i, line in enumerate(content):\n+            if re.match(r'^\\s*={3,}\\s*$', line) or re.match(r'^\\s*-{3,}\\s*$', line):\n+                heading_found = True\n+                pos = i + 1\n+                break\n             if docinfo_re.match(line):\n                 pos += 1\n             else:\n                 break\n \n-        if pos > 0:\n-            # insert a blank line after docinfo\n+        if pos > 0 and not heading_found:\n             content.insert(pos, '', '<generated>', 0)\n             pos += 1\n \n-        # insert prolog (after docinfo if exists)\n         for lineno, line in enumerate(prolog.splitlines()):\n             content.insert(pos + lineno, line, '<rst_prolog>', lineno)\n \n         content.insert(pos + lineno + 1, '', '<generated>', 0)\n \n+        if heading_found:\n+            for i, line in enumerate(content):\n+                if re.match(r'^\\s*:\\w+:`.*`\\s*$', line):\n+                    content.pop(i)\n+                    break\n+\n \n def append_epilog(content: StringList, epilog: str) -> None:\n     \"\"\"Append a string to content body as epilog.\"\"\"", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sphinx-doc__sphinx-8435", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -2093,7 +2093,7 @@ class AttributeDocumenter(DocstringStripSignatureMixin, ClassLevelDocumenter):\n         if not self.options.annotation:\n             # obtain type annotation for this attribute\n             try:\n-                annotations = get_type_hints(self.parent)\n+                annotations = get_type_hints(self.parent, globalns=None, localns=self.config.autodoc_type_aliases)\n             except NameError:\n                 # Failed to evaluate ForwardRef (maybe TYPE_CHECKING)\n                 annotations = safe_getattr(self.parent, '__annotations__', {})", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-13043", "model_patch": "diff --git a/sympy/integrals/intpoly.py b/sympy/integrals/intpoly.py\n--- a/sympy/integrals/intpoly.py\n+++ b/sympy/integrals/intpoly.py\n@@ -569,7 +569,7 @@ def decompose(expr, separate=False):\n             degrees = [(sum(degree_list(monom, *symbols)), monom)\n                        for monom in expr.args]\n             if separate:\n-                return [monom[1] for monom in degrees]\n+                return [monom[1] for monom in sorted(degrees)]\n             else:\n                 for monom in degrees:\n                     degree, term = monom\n@@ -593,7 +593,7 @@ def decompose(expr, separate=False):\n         poly_dict[0] = expr\n \n     if separate:\n-        return list(poly_dict.values())\n+        return [poly_dict[key] for key in sorted(poly_dict)]\n     return poly_dict", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-13971", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1655,9 +1655,9 @@ def _print_SeqFormula(self, s):\n         else:\n             printset = tuple(s)\n \n-        return (r\"\\left\\[\"\n+        return (r\"[\"\n               + r\", \".join(self._print(el) for el in printset)\n-              + r\"\\right\\]\")\n+              + r\"]\")\n \n     _print_SeqPer = _print_SeqFormula\n     _print_SeqAdd = _print_SeqFormula", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-14396", "model_patch": "diff --git a/sympy/polys/polyoptions.py b/sympy/polys/polyoptions.py\n--- a/sympy/polys/polyoptions.py\n+++ b/sympy/polys/polyoptions.py\n@@ -480,7 +480,11 @@ def preprocess(cls, domain):\n                 gens = list(map(sympify, r.groups()[1].split(',')))\n                 return sympy.polys.domains.QQ.algebraic_field(*gens)\n \n-        raise OptionError('expected a valid domain specification, got %s' % domain)\n+            if domain.startswith('RR[') and domain.endswith(']'):\n+                gens = list(map(sympify, domain[3:-1].split(',')))\n+                return sympy.polys.domains.RR.poly_ring(*gens)\n+\n+        raise OptionError('Expected a valid domain specification, but got: %s' % domain)\n \n     @classmethod\n     def postprocess(cls, options):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-15345", "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -31,7 +31,8 @@\n     \"asech\": [(lambda x: True, \"ArcSech\")],\n     \"acsch\": [(lambda x: True, \"ArcCsch\")],\n     \"conjugate\": [(lambda x: True, \"Conjugate\")],\n-\n+    \"Max\": [(lambda *args: True, \"Max\")],  # Accepting any number of arguments.\n+    \"Min\": [(lambda *args: True, \"Min\")],  # Accepting any number of arguments.\n }\n \n \n@@ -101,6 +102,8 @@ def _print_Function(self, expr):\n                     return \"%s[%s]\" % (mfunc, self.stringify(expr.args, \", \"))\n         return expr.func.__name__ + \"[%s]\" % self.stringify(expr.args, \", \")\n \n+    _print_MinMaxBase = _print_Function  # Function to handle Min and Max.\n+\n     def _print_Integral(self, expr):\n         if len(expr.variables) == 1 and not expr.limits[0][1:]:\n             args = [expr.args[0], expr.variables[0]]", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-16281", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -479,7 +479,6 @@ def _print_Product(self, expr):\n         vertical_chr = xobj('|', 1)\n \n         if self._use_unicode:\n-            # use unicode corners\n             horizontal_chr = xobj('-', 1)\n             corner_chr = u'\\N{BOX DRAWINGS LIGHT DOWN AND HORIZONTAL}'\n \n@@ -490,10 +489,10 @@ def _print_Product(self, expr):\n         sign_height = 0\n \n         for lim in expr.limits:\n-            width = (func_height + 2) * 5 // 3 - 2\n+            width = (func_height + 2) * 3 // 2 - 2\n             sign_lines = []\n-            sign_lines.append(corner_chr + (horizontal_chr*width) + corner_chr)\n-            for i in range(func_height + 1):\n+            sign_lines.append(horizontal_chr + (horizontal_chr*width) + horizontal_chr)\n+            for i in range(func_height):\n                 sign_lines.append(vertical_chr + (' '*width) + vertical_chr)\n \n             pretty_sign = stringPict('')\n@@ -516,7 +515,7 @@ def _print_Product(self, expr):\n \n             height = pretty_sign.height()\n             padding = stringPict('')\n-            padding = prettyForm(*padding.stack(*[' ']*(height - 1)))\n+            padding = prettyForm(*padding.stack(*[' ']*(height - 2)))\n             pretty_sign = prettyForm(*pretty_sign.right(padding))\n \n             pretty_func = prettyForm(*pretty_sign.right(pretty_func))", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-16792", "model_patch": "diff --git a/sympy/utilities/codegen.py b/sympy/utilities/codegen.py\n--- a/sympy/utilities/codegen.py\n+++ b/sympy/utilities/codegen.py\n@@ -695,6 +695,11 @@ def routine(self, name, expr, argument_sequence=None, global_vars=None):\n         arg_list = []\n \n         # setup input argument list\n+\n+        # helper function to retrieve dimensions for array-like arguments\n+        def dimensions(s):\n+            return [(S.Zero, dim - 1) for dim in s.shape]\n+\n         array_symbols = {}\n         for array in expressions.atoms(Indexed) | local_expressions.atoms(Indexed):\n             array_symbols[array.base.label] = array\n@@ -703,11 +708,8 @@ def routine(self, name, expr, argument_sequence=None, global_vars=None):\n \n         for symbol in sorted(symbols, key=str):\n             if symbol in array_symbols:\n-                dims = []\n                 array = array_symbols[symbol]\n-                for dim in array.shape:\n-                    dims.append((S.Zero, dim - 1))\n-                metadata = {'dimensions': dims}\n+                metadata = {'dimensions': dimensions(array)}\n             else:\n                 metadata = {}\n \n@@ -739,7 +741,11 @@ def routine(self, name, expr, argument_sequence=None, global_vars=None):\n                 try:\n                     new_args.append(name_arg_dict[symbol])\n                 except KeyError:\n-                    new_args.append(InputArgument(symbol))\n+                    if isinstance(symbol, (IndexedBase, MatrixSymbol)):\n+                        metadata = {'dimensions': dimensions(symbol)}\n+                    else:\n+                        metadata = {}\n+                    new_args.append(InputArgument(symbol, **metadata))\n             arg_list = new_args\n \n         return Routine(name, arg_list, return_val, local_vars, global_vars)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-16988", "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -1260,7 +1260,7 @@ def __new__(cls, *args, **kwargs):\n         evaluate = kwargs.get('evaluate', global_evaluate[0])\n \n         # flatten inputs to merge intersections and iterables\n-        args = _sympify(args)\n+        args = list(ordered(set(_sympify(args))))  # Ensuring uniqueness and order\n \n         # Reduce sets using known rules\n         if evaluate:", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-19007", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -244,7 +244,7 @@ def _entry(self, i, j, **kwargs):\n                 break\n             else:\n                 j -= numcols\n-        return self.blocks[row_block, col_block][i, j]\n+        return self.blocks[row_block, col_block]._entry(i, j, **kwargs)\n \n     @property\n     def is_Identity(self):", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-21612", "model_patch": "diff --git a/sympy/printing/str.py b/sympy/printing/str.py\n--- a/sympy/printing/str.py\n+++ b/sympy/printing/str.py\n@@ -333,7 +333,7 @@ def apow(i):\n                     b.append(apow(item))\n                 else:\n                     if (len(item.args[0].args) != 1 and\n-                            isinstance(item.base, Mul)):\n+                            isinstance(item.base, (Mul, Pow))):  # type: Union[Mul, Pow]\n                         # To avoid situations like #14160\n                         pow_paren.append(item)\n                     b.append(item.base)", "model_name_or_path": "MoatlessToolsplusGPT4o"}
{"instance_id": "sympy__sympy-24102", "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -654,7 +654,7 @@ def _from_mathematica_to_tokens(self, code: str):\n             code_splits[i] = code_split\n\n         # Tokenize the input strings with a regular expression:\n-        token_lists = [tokenizer.findall(i) if isinstance(i, str) else [i] for i in code_splits]\n+        token_lists = [tokenizer.findall(i) if isinstance(i, str) and i.isascii() else [i] for i in code_splits]\n         tokens = [j for i in token_lists for j in i]\n\n         # Remove newlines at the beginning", "model_name_or_path": "MoatlessToolsplusGPT4o"}
